{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"<code>scientific_pydantic</code>","text":"<p><code>scientific_pydantic</code> is an extension module to <code>pydantic</code> that adds support for a number of common data types in scientific computing.</p>"},{"location":"#motivation","title":"Motivation","text":"<p>Let's say with only <code>pydantic</code>, you wanted to put a <code>numpy.ndarray</code> object into one of your models: <pre><code>import numpy as np\nimport pydantic\n\nclass MyModel(pydantic.BaseModel):\n    arr: np.ndarray\n</code></pre> this will produce the following error: <pre><code>pydantic.errors.PydanticSchemaGenerationError: Unable to generate pydantic-core schema for &lt;class 'numpy.ndarray'&gt;. Set `arbitrary_types_allowed=True` in the model_config to ignore this error or implement `__get_pydantic_core_schema__` on your type to fully support it.\n</code></pre> Specifying <code>arbitrary_types_allowed=True</code> can work, but disables JSON serialization and validation and does not support lax parsing and input conversions, which are a powerful feature of pydantic. This library takes the approach of implementing <code>__get_pydantic_core_schema__</code> in adapter objects and using <code>Annotated</code>, as described here.</p> <p>With <code>scientific_pydantic</code>, this example looks like: <pre><code>import typing as ty\n\nimport numpy as np\nimport pydantic\nfrom scientific_pydantic.numpy import NDArrayAdapter\n\nclass MyModel(pydantic.BaseModel):\n    arr: ty.Annotated[np.ndarray, NDArrayAdapter()]\n</code></pre> Using this pattern, you can embed scientific data types into your models and get the full <code>pydantic</code> experience with serialization and input conversions.</p>"},{"location":"#usage","title":"Usage","text":"<p>In general, it is recommended to use <code>from</code>-style imports with this library. The import path for an adapter is normally akin to the import path of the type it is adapting. For instance, the adapter for <code>scipy.spatial.transform.Rotation</code> would be: <pre><code>from scientific_pydantic.scipy.spatial.transform import RotationAdapter\n</code></pre> Adapters are used via the <code>Annotated</code> pattern, as was shown in the Motivation section. This allows for typecheckers that support <code>pydantic</code>, such as <code>pyrefly</code> to understand the type of the fields.</p> <p>A number of adapters provided with this library also take parameters that define common validation operations. This takes inspiration from <code>pydantic.Field</code>. For instance, <pre><code>import pydantic\n\nclass MyModel(pydantic.BaseModel):\n    a: int = pydantic.Field(ge=0)\n</code></pre> defines a non-negative integer. In <code>scientific_pydantic</code>, this style of validation logic can be accomplished via: <pre><code>import typing as ty\n\nimport numpy as np\nimport pydantic\nfrom scientific_pydantic.numpy import NDArrayAdapter\n\nclass MyModel(pydantic.BaseModel):\n    a: ty.Annotated[np.ndarray, NDArrayAdapter(shape=(None, 3), ge=0)]\n</code></pre> which constrains <code>a</code> to be an <code>N x 3</code> <code>ndarray</code> where all elements are non-negative. See the individual adapters in the API documentation for a description of the parameters each one takes.</p>"},{"location":"#design-philosophy","title":"Design Philosophy","text":"<p>This library has an interesting conundrum from a dependency standpoint. Since the goal is to provide adapters for common types that come from many different libraries, there are a few options for how dependency management can work:</p> <ol> <li>Depend on all packages being supported and enforce version constraints. This    would violate the \"pay for what you use\" principle and is thus not a good    option.</li> <li>Split the package into <code>N</code> different, but related, packages (e.g.    <code>scientific_pydantic_shapely</code>) that enforce version constraints individually.    This is tractable, but leads to a large number of packages to maintain and    version together.</li> <li>Have 1 package and only depend on <code>pydantic</code> (and <code>pydantic_core</code>). Users    will bring their own versions of the packages they want to use.</li> </ol> <p>This library takes approach #3. This puts the burden of version compatibility onto this library. For instance, <code>scipy.spatial.transform.Rotation</code> objects gained the ability to support N-D arrays of rotation transforms in version 1.17.0. Thus, validation features related to this must be disabled if the user brings their own <code>scipy</code> version that is <code>&lt; 1.17.0</code>. This adds complexity to this library, but prevents either the dependency bloat from option 1 or the package bloat from option 2.</p> <p>By only depending on <code>pydantic</code>, the library must not import anything from a third-party library at global scope. This is accomplished via liberal use of delayed and nested import statments and enforced via a unit test.</p>"},{"location":"SUMMARY/","title":"SUMMARY","text":"<ul> <li>Home</li> <li>API Reference<ul> <li>astropy<ul> <li>time</li> <li>units</li> </ul> </li> <li>numpy</li> <li>scipy<ul> <li>spatial<ul> <li>transform</li> </ul> </li> </ul> </li> <li>shapely</li> </ul> </li> </ul>"},{"location":"api/scientific_pydantic/","title":"<code>scientific_pydantic</code>","text":"<pre><code>import scientific_pydantic\n</code></pre>"},{"location":"api/scientific_pydantic/#scientific_pydantic","title":"<code>scientific_pydantic</code>","text":"<p>Pydantic adapters for common scientific libraries</p> <p>Adapters in the root of this package are for Python standard library types ONLY.</p> <p>The current supported types from the standard library (above and beyond what <code>pydantic</code> already supports) are:</p> <ul> <li><code>Ellipsis</code> - EllipsisAdapter</li> <li><code>range</code> - RangeAdapter</li> <li><code>slice</code> - SliceAdapter</li> </ul> <p>Subpackages shall follow the structure of their library and exist at the same path as the type they are adapting. For instance, the adapter <code>astropy.units.UnitBase</code> lives in <code>scientific_pydantic.astropy.units</code>.</p>"},{"location":"api/scientific_pydantic/#scientific_pydantic.EllipsisLiteral","title":"<code>EllipsisLiteral = ty.Annotated[types.EllipsisType, EllipsisAdapter()]</code>  <code>module-attribute</code>","text":""},{"location":"api/scientific_pydantic/#scientific_pydantic.IntSliceAdapter","title":"<code>IntSliceAdapter = SliceAdapter(int | None)</code>  <code>module-attribute</code>","text":""},{"location":"api/scientific_pydantic/#scientific_pydantic.EllipsisAdapter","title":"<code>EllipsisAdapter</code>","text":"<p>A Pydantic annotation for the <code>Ellipsis</code> singleton (<code>...</code>).</p> <p>In general, you should use the publicly-defined alias EllipsisLiteral to express when you want <code>...</code> stored in your model.</p> Validation Options <ol> <li><code>Ellipsis</code>/<code>...</code>: Identity.</li> <li><code>ty.Literal[\"...\"]</code> - The string \"...\". This is used in JSON encoding.</li> </ol> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pydantic\n&gt;&gt;&gt; from scientific_pydantic import (\n...     EllipsisLiteral,\n... )\n\n&gt;&gt;&gt; class Model(pydantic.BaseModel):\n...     shape: list[EllipsisLiteral | int]\n\n&gt;&gt;&gt; Model(shape=[1, ..., 2])\nModel(shape=[1, Ellipsis, 2])\n</code></pre> Source code in <code>src/scientific_pydantic/ellipsis.py</code> <pre><code>class EllipsisAdapter:\n    \"\"\"A Pydantic annotation for the `Ellipsis` singleton (`...`).\n\n    In general, you should use the publicly-defined alias\n    [EllipsisLiteral][scientific_pydantic.EllipsisLiteral] to express when you\n    want `...` stored in your model.\n\n    Validation Options\n    ------------------\n    1. `Ellipsis`/`...`: Identity.\n    2. `ty.Literal[\"...\"]` - The string \"...\". This is used in JSON encoding.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pydantic\n    &gt;&gt;&gt; from scientific_pydantic import (\n    ...     EllipsisLiteral,\n    ... )  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; class Model(pydantic.BaseModel):\n    ...     shape: list[EllipsisLiteral | int]  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; Model(shape=[1, ..., 2])\n    Model(shape=[1, Ellipsis, 2])\n    \"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source_type: ty.Any, handler: pydantic.GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        \"\"\"Get the pydantic schema for this type\"\"\"\n        del handler\n\n        if source_type is not types.EllipsisType and not (\n            ty.get_origin(source_type) is ty.Literal\n            and len(args := ty.get_args(source_type)) &gt; 0\n            and args[0] is Ellipsis\n        ):\n            msg = (\n                \"EllipsisAdapter is only usable with EllipsisType or \"\n                f\"Literal[Ellipsis], not {source_type}\"\n            )\n            raise pydantic.PydanticSchemaGenerationError(msg)\n\n        return core_schema.no_info_plain_validator_function(\n            cls._validate,\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                lambda _: \"...\",\n                when_used=\"json\",\n            ),\n        )\n\n    @classmethod\n    def _validate(cls, value: ty.Any) -&gt; types.EllipsisType:\n        if value is ... or value == \"...\":\n            return ...\n        msg = f\"Expected Ellipsis (...), got {value!r}\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"api/scientific_pydantic/#scientific_pydantic.EllipsisAdapter.__get_pydantic_core_schema__","title":"<code>__get_pydantic_core_schema__(source_type: ty.Any, handler: pydantic.GetCoreSchemaHandler) -&gt; core_schema.CoreSchema</code>  <code>classmethod</code>","text":"<p>Get the pydantic schema for this type</p> Source code in <code>src/scientific_pydantic/ellipsis.py</code> <pre><code>@classmethod\ndef __get_pydantic_core_schema__(\n    cls, source_type: ty.Any, handler: pydantic.GetCoreSchemaHandler\n) -&gt; core_schema.CoreSchema:\n    \"\"\"Get the pydantic schema for this type\"\"\"\n    del handler\n\n    if source_type is not types.EllipsisType and not (\n        ty.get_origin(source_type) is ty.Literal\n        and len(args := ty.get_args(source_type)) &gt; 0\n        and args[0] is Ellipsis\n    ):\n        msg = (\n            \"EllipsisAdapter is only usable with EllipsisType or \"\n            f\"Literal[Ellipsis], not {source_type}\"\n        )\n        raise pydantic.PydanticSchemaGenerationError(msg)\n\n    return core_schema.no_info_plain_validator_function(\n        cls._validate,\n        serialization=core_schema.plain_serializer_function_ser_schema(\n            lambda _: \"...\",\n            when_used=\"json\",\n        ),\n    )\n</code></pre>"},{"location":"api/scientific_pydantic/#scientific_pydantic.RangeAdapter","title":"<code>RangeAdapter</code>","text":"<p>Pydantic adapter for Python <code>range</code> using slice syntax.</p> Validation Options <ol> <li><code>range</code> - Identity</li> <li><code>str</code> - A slice-like syntax (<code>[start:]stop[:step]</code>) is used. This     representation is also used for the JSON encoding of range.</li> </ol> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import typing as ty\n&gt;&gt;&gt; import pydantic\n&gt;&gt;&gt; from scientific_pydantic import RangeAdapter\n\n&gt;&gt;&gt; class Model(pydantic.BaseModel):\n...     field: ty.Annotated[range, RangeAdapter()]\n\n&gt;&gt;&gt; Model(field=\"12:25:2\")\nModel(field=range(12, 25, 2))\n&gt;&gt;&gt; Model(field=range(12, 25, 2))\nModel(field=range(12, 25, 2))\n</code></pre> Source code in <code>src/scientific_pydantic/range.py</code> <pre><code>class RangeAdapter:\n    \"\"\"Pydantic adapter for Python `range` using slice syntax.\n\n    Validation Options\n    ------------------\n    1. `range` - Identity\n    2. `str` - A slice-like syntax (`[start:]stop[:step]`) is used. This\n        representation is also used for the JSON encoding of range.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import typing as ty\n    &gt;&gt;&gt; import pydantic\n    &gt;&gt;&gt; from scientific_pydantic import RangeAdapter  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; class Model(pydantic.BaseModel):\n    ...     field: ty.Annotated[range, RangeAdapter()]  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; Model(field=\"12:25:2\")\n    Model(field=range(12, 25, 2))\n    &gt;&gt;&gt; Model(field=range(12, 25, 2))\n    Model(field=range(12, 25, 2))\n    \"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls,\n        _source_type: ty.Any,\n        _handler: pydantic.GetCoreSchemaHandler,\n    ) -&gt; core_schema.CoreSchema:\n        \"\"\"Get the pydantic schema for this type\"\"\"\n\n        def _validate(value: ty.Any) -&gt; range:\n            if isinstance(value, range):\n                return value\n\n            if isinstance(value, str):\n                try:\n                    start, stop, step = parse_slice_syntax(\n                        value,\n                        converter=int,\n                        require_start=False,\n                        require_stop=True,\n                    )\n                except SliceSyntaxError as exc:\n                    raise ValueError(str(exc)) from exc\n\n                return range(\n                    start if start is not None else 0,\n                    stop,\n                    step if step is not None else 1,\n                )\n\n            msg = \"Expected range or slice-syntax string\"\n            raise ValueError(msg)\n\n        def _serialize(value: range) -&gt; str:\n            step = None if value.step == 1 else value.step\n            return format_slice_syntax(value.start, value.stop, step)\n\n        return core_schema.no_info_plain_validator_function(\n            _validate,\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                _serialize,\n                when_used=\"json\",\n            ),\n        )\n\n    @classmethod\n    def __get_pydantic_json_schema__(\n        cls,\n        _core_schema: core_schema.CoreSchema,\n        _handler: pydantic.GetJsonSchemaHandler,\n    ) -&gt; JsonSchemaValue:\n        \"\"\"Get the JSON schema for this type\"\"\"\n        return {\n            \"type\": \"string\",\n            \"title\": \"range\",\n            \"description\": \"Python range syntax: start:stop[:step]\",\n            \"pattern\": r\"^\\s*-?\\d+\\s*:\\s*-?\\d+\\s*(?::\\s*-?\\d+\\s*)?$\",\n        }\n</code></pre>"},{"location":"api/scientific_pydantic/#scientific_pydantic.RangeAdapter.__get_pydantic_core_schema__","title":"<code>__get_pydantic_core_schema__(_source_type: ty.Any, _handler: pydantic.GetCoreSchemaHandler) -&gt; core_schema.CoreSchema</code>  <code>classmethod</code>","text":"<p>Get the pydantic schema for this type</p> Source code in <code>src/scientific_pydantic/range.py</code> <pre><code>@classmethod\ndef __get_pydantic_core_schema__(\n    cls,\n    _source_type: ty.Any,\n    _handler: pydantic.GetCoreSchemaHandler,\n) -&gt; core_schema.CoreSchema:\n    \"\"\"Get the pydantic schema for this type\"\"\"\n\n    def _validate(value: ty.Any) -&gt; range:\n        if isinstance(value, range):\n            return value\n\n        if isinstance(value, str):\n            try:\n                start, stop, step = parse_slice_syntax(\n                    value,\n                    converter=int,\n                    require_start=False,\n                    require_stop=True,\n                )\n            except SliceSyntaxError as exc:\n                raise ValueError(str(exc)) from exc\n\n            return range(\n                start if start is not None else 0,\n                stop,\n                step if step is not None else 1,\n            )\n\n        msg = \"Expected range or slice-syntax string\"\n        raise ValueError(msg)\n\n    def _serialize(value: range) -&gt; str:\n        step = None if value.step == 1 else value.step\n        return format_slice_syntax(value.start, value.stop, step)\n\n    return core_schema.no_info_plain_validator_function(\n        _validate,\n        serialization=core_schema.plain_serializer_function_ser_schema(\n            _serialize,\n            when_used=\"json\",\n        ),\n    )\n</code></pre>"},{"location":"api/scientific_pydantic/#scientific_pydantic.RangeAdapter.__get_pydantic_json_schema__","title":"<code>__get_pydantic_json_schema__(_core_schema: core_schema.CoreSchema, _handler: pydantic.GetJsonSchemaHandler) -&gt; JsonSchemaValue</code>  <code>classmethod</code>","text":"<p>Get the JSON schema for this type</p> Source code in <code>src/scientific_pydantic/range.py</code> <pre><code>@classmethod\ndef __get_pydantic_json_schema__(\n    cls,\n    _core_schema: core_schema.CoreSchema,\n    _handler: pydantic.GetJsonSchemaHandler,\n) -&gt; JsonSchemaValue:\n    \"\"\"Get the JSON schema for this type\"\"\"\n    return {\n        \"type\": \"string\",\n        \"title\": \"range\",\n        \"description\": \"Python range syntax: start:stop[:step]\",\n        \"pattern\": r\"^\\s*-?\\d+\\s*:\\s*-?\\d+\\s*(?::\\s*-?\\d+\\s*)?$\",\n    }\n</code></pre>"},{"location":"api/scientific_pydantic/#scientific_pydantic.SliceAdapter","title":"<code>SliceAdapter</code>","text":"<p>Pydantic adapter for Python's built-in <code>slice</code>.</p> <p><code>slice</code> is more complex than <code>range</code> in that it is essentially a generic 3-tuple (<code>tuple[Any, Any, Any]</code>). Integer values are only required if/when the user calls <code>.indices()</code> on the <code>slice</code>. There are a number of other valid uses of <code>slice</code> that do not use integers as the elements and thus this adapter supports non-integer elements.</p> <p>A public alias IntSliceAdapter is exposed for <code>SliceAdapter(int | None)</code>.</p> Validation Options <ol> <li><code>slice</code> - Identity.</li> <li><code>str</code> - A string of the format <code>\"[start]:[stop][:step]\"</code>. This is also    used as the JSON representation when all elements are either numeric    or <code>None</code>.</li> <li><code>Mapping</code> - A mapping with <code>\"start\"</code>, <code>\"stop\"</code> and <code>\"step\"</code> keys    (all optional). This is used as the JSON representation when the    conditions for an <code>str</code> encoding are not met.</li> <li><code>Sequence</code> - A sequence of length 1, 2 or 3 with generic elements.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>default_type</code> <code>Hashable</code> <p>The default type annotation for all 3 elements of the slice. This should normally include <code>None</code> unless all 3 elements are always required..</p> <code>Any</code> <code>start_type</code> <code>Hashable</code> <p>If given, overrides <code>default_type</code> as the type annotation for the start of the slice.</p> <code>UNSET</code> <code>stop_type</code> <code>Hashable</code> <p>If given, overrides <code>default_type</code> as the type annotation for the stop of the slice.</p> <code>UNSET</code> <code>step_type</code> <code>Hashable</code> <p>If given, overrides <code>default_type</code> as the type annotation for the step of the slice.</p> <code>UNSET</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pydantic\n&gt;&gt;&gt; from scientific_pydantic import SliceAdapter\n\n&gt;&gt;&gt; class Model(pydantic.BaseModel):\n...     s: ty.Annotated[\n...         slice, SliceAdapter(int | None)\n...     ]\n\n&gt;&gt;&gt; Model(s=slice(1, 3))\nModel(s=slice(1, 3, None))\n&gt;&gt;&gt; Model(s=\"1:10:2\")\nModel(s=slice(1, 10, 2))\n&gt;&gt;&gt; Model(s={\"start\": 1})\nModel(s=slice(1, None, None))\n</code></pre> Source code in <code>src/scientific_pydantic/slice.py</code> <pre><code>class SliceAdapter:\n    \"\"\"Pydantic adapter for Python's built-in `slice`.\n\n    `slice` is more complex than `range` in that it is essentially a generic\n    3-tuple (`tuple[Any, Any, Any]`). Integer values are only required if/when\n    the user calls `.indices()` on the `slice`. There are a number of other\n    valid uses of `slice` that do not use integers as the elements and thus\n    this adapter supports non-integer elements.\n\n    A public alias [IntSliceAdapter][scientific_pydantic.IntSliceAdapter] is\n    exposed for `SliceAdapter(int | None)`.\n\n    Validation Options\n    ------------------\n    1. `slice` - Identity.\n    2. `str` - A string of the format `\"[start]:[stop][:step]\"`. This is also\n       used as the JSON representation when all elements are either numeric\n       or `None`.\n    3. `Mapping` - A mapping with `\"start\"`, `\"stop\"` and `\"step\"` keys\n       (all optional). This is used as the JSON representation when the\n       conditions for an `str` encoding are not met.\n    4. `Sequence` - A sequence of length 1, 2 or 3 with generic elements.\n\n    Parameters\n    ----------\n    default_type : Hashable\n        The default type annotation for all 3 elements of the slice. This should\n        normally include `None` unless all 3 elements are always required..\n    start_type : Hashable\n        If given, overrides `default_type` as the type annotation for the start\n        of the slice.\n    stop_type : Hashable\n        If given, overrides `default_type` as the type annotation for the stop\n        of the slice.\n    step_type : Hashable\n        If given, overrides `default_type` as the type annotation for the step\n        of the slice.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pydantic\n    &gt;&gt;&gt; from scientific_pydantic import SliceAdapter  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; class Model(pydantic.BaseModel):\n    ...     s: ty.Annotated[\n    ...         slice, SliceAdapter(int | None)\n    ...     ]  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; Model(s=slice(1, 3))\n    Model(s=slice(1, 3, None))\n    &gt;&gt;&gt; Model(s=\"1:10:2\")\n    Model(s=slice(1, 10, 2))\n    &gt;&gt;&gt; Model(s={\"start\": 1})\n    Model(s=slice(1, None, None))\n    \"\"\"\n\n    def __init__(\n        self,\n        default_type: Hashable = ty.Any,\n        *,\n        start_type: Hashable = UNSET,\n        stop_type: Hashable = UNSET,\n        step_type: Hashable = UNSET,\n    ) -&gt; None:\n        adapters = {\n            t: pydantic.TypeAdapter(t)\n            for t in {default_type, start_type, stop_type, step_type}\n            if t is not UNSET\n        }\n        self._default_adapter = adapters[default_type]\n        self._start_adapter = (\n            adapters[start_type] if start_type is not UNSET else self._default_adapter\n        )\n        self._stop_adapter = (\n            adapters[stop_type] if stop_type is not UNSET else self._default_adapter\n        )\n        self._step_adapter = (\n            adapters[step_type] if step_type is not UNSET else self._default_adapter\n        )\n\n    def __get_pydantic_core_schema__(\n        self,\n        _source_type: ty.Any,\n        _handler: pydantic.GetCoreSchemaHandler,\n    ) -&gt; core_schema.CoreSchema:\n        \"\"\"Get the pydantic schema for this type\"\"\"\n\n        def _validate(value: ty.Any) -&gt; slice:\n            match value:\n                case slice():\n                    return value\n                case Mapping():\n                    start, stop, step = _from_mapping(value)\n                case str():\n                    start, stop, step = _from_str(value)\n                case Sequence():\n                    start, stop, step = _from_sequence(value)\n                case _:\n                    msg = \"Expected a slice, sequence, mapping or str\"\n                    raise ValueError(msg)\n\n            start = self._start_adapter.validate_python(start)\n            stop = self._stop_adapter.validate_python(stop)\n            step = self._step_adapter.validate_python(step)\n            return slice(start, stop, step)\n\n        def _serialize(value: slice) -&gt; str | dict[str, ty.Any]:\n            if all(\n                x is None or isinstance(x, numbers.Number)\n                for x in (value.start, value.stop, value.step)\n            ):\n                return format_slice_syntax(value.start, value.stop, value.step)\n\n            return {\n                \"start\": value.start,\n                \"stop\": value.stop,\n                \"step\": value.step,\n            }\n\n        return core_schema.no_info_plain_validator_function(\n            _validate,\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                _serialize,\n                when_used=\"json\",\n            ),\n        )\n\n    def __get_pydantic_json_schema__(\n        self,\n        _core_schema: core_schema.CoreSchema,\n        handler: pydantic.GetJsonSchemaHandler,\n    ) -&gt; JsonSchemaValue:\n        \"\"\"Get the JSON schema for this object\"\"\"\n        return handler(\n            core_schema.union_schema(\n                [\n                    core_schema.str_schema(),\n                    core_schema.list_schema(min_length=1, max_length=3),\n                    core_schema.typed_dict_schema(\n                        {\n                            \"start\": core_schema.typed_dict_field(\n                                self._start_adapter.core_schema\n                                if self._start_adapter is not None\n                                else core_schema.any_schema(),\n                            ),\n                            \"stop\": core_schema.typed_dict_field(\n                                self._stop_adapter.core_schema\n                                if self._stop_adapter is not None\n                                else core_schema.any_schema(),\n                            ),\n                            \"step\": core_schema.typed_dict_field(\n                                self._step_adapter.core_schema\n                                if self._step_adapter is not None\n                                else core_schema.any_schema(),\n                            ),\n                        },\n                        total=False,\n                    ),\n                ],\n            ),\n        )\n</code></pre>"},{"location":"api/scientific_pydantic/#scientific_pydantic.SliceAdapter.__get_pydantic_core_schema__","title":"<code>__get_pydantic_core_schema__(_source_type: ty.Any, _handler: pydantic.GetCoreSchemaHandler) -&gt; core_schema.CoreSchema</code>","text":"<p>Get the pydantic schema for this type</p> Source code in <code>src/scientific_pydantic/slice.py</code> <pre><code>def __get_pydantic_core_schema__(\n    self,\n    _source_type: ty.Any,\n    _handler: pydantic.GetCoreSchemaHandler,\n) -&gt; core_schema.CoreSchema:\n    \"\"\"Get the pydantic schema for this type\"\"\"\n\n    def _validate(value: ty.Any) -&gt; slice:\n        match value:\n            case slice():\n                return value\n            case Mapping():\n                start, stop, step = _from_mapping(value)\n            case str():\n                start, stop, step = _from_str(value)\n            case Sequence():\n                start, stop, step = _from_sequence(value)\n            case _:\n                msg = \"Expected a slice, sequence, mapping or str\"\n                raise ValueError(msg)\n\n        start = self._start_adapter.validate_python(start)\n        stop = self._stop_adapter.validate_python(stop)\n        step = self._step_adapter.validate_python(step)\n        return slice(start, stop, step)\n\n    def _serialize(value: slice) -&gt; str | dict[str, ty.Any]:\n        if all(\n            x is None or isinstance(x, numbers.Number)\n            for x in (value.start, value.stop, value.step)\n        ):\n            return format_slice_syntax(value.start, value.stop, value.step)\n\n        return {\n            \"start\": value.start,\n            \"stop\": value.stop,\n            \"step\": value.step,\n        }\n\n    return core_schema.no_info_plain_validator_function(\n        _validate,\n        serialization=core_schema.plain_serializer_function_ser_schema(\n            _serialize,\n            when_used=\"json\",\n        ),\n    )\n</code></pre>"},{"location":"api/scientific_pydantic/#scientific_pydantic.SliceAdapter.__get_pydantic_json_schema__","title":"<code>__get_pydantic_json_schema__(_core_schema: core_schema.CoreSchema, handler: pydantic.GetJsonSchemaHandler) -&gt; JsonSchemaValue</code>","text":"<p>Get the JSON schema for this object</p> Source code in <code>src/scientific_pydantic/slice.py</code> <pre><code>def __get_pydantic_json_schema__(\n    self,\n    _core_schema: core_schema.CoreSchema,\n    handler: pydantic.GetJsonSchemaHandler,\n) -&gt; JsonSchemaValue:\n    \"\"\"Get the JSON schema for this object\"\"\"\n    return handler(\n        core_schema.union_schema(\n            [\n                core_schema.str_schema(),\n                core_schema.list_schema(min_length=1, max_length=3),\n                core_schema.typed_dict_schema(\n                    {\n                        \"start\": core_schema.typed_dict_field(\n                            self._start_adapter.core_schema\n                            if self._start_adapter is not None\n                            else core_schema.any_schema(),\n                        ),\n                        \"stop\": core_schema.typed_dict_field(\n                            self._stop_adapter.core_schema\n                            if self._stop_adapter is not None\n                            else core_schema.any_schema(),\n                        ),\n                        \"step\": core_schema.typed_dict_field(\n                            self._step_adapter.core_schema\n                            if self._step_adapter is not None\n                            else core_schema.any_schema(),\n                        ),\n                    },\n                    total=False,\n                ),\n            ],\n        ),\n    )\n</code></pre>"},{"location":"api/scientific_pydantic/astropy/","title":"<code>astropy</code>","text":"<pre><code>import scientific_pydantic.astropy\n</code></pre> <p>See subpackages below.</p>"},{"location":"api/scientific_pydantic/astropy/time/","title":"<code>time</code>","text":"<pre><code>import scientific_pydantic.astropy.time\n</code></pre>"},{"location":"api/scientific_pydantic/astropy/time/#scientific_pydantic.astropy.time","title":"<code>time</code>","text":"<p>Pydantic adapters for astropy.time</p> <p>The current supported types are:</p> <ul> <li><code>Time</code> - <code>TimeAdapter</code></li> </ul>"},{"location":"api/scientific_pydantic/astropy/time/#scientific_pydantic.astropy.time.TimeAdapter","title":"<code>TimeAdapter</code>","text":"<p>Pydantic adapter for astropy.time.Time</p> Validation Options <ol> <li><code>Time</code> - Identity.</li> <li><code>Time</code>-like object - Any object that can be passed directly to the <code>Time</code>    constructor, such an ISO-8601 string or a <code>datetime.datetime</code> (or an    <code>ArrayLike</code> of these objects).</li> <li><code>Mapping</code> - A mapping of constructor arguments to <code>Time</code>. <code>val</code> and     <code>val2</code> can also be passed as <code>\"value\"</code>/<code>\"value2\"</code> keys.</li> </ol> JSON Serialization <p><code>Time</code>s are serialized in JSON as the <code>Mapping</code> option. If the <code>precision</code> of the <code>Time</code> object is &gt; 6 (microsecond), then the format is converted to <code>jd</code> and <code>jd1</code> and <code>jd2</code> are used for <code>\"value\"</code> and <code>\"value2\"</code>. Otherwise, the <code>Time</code>'s <code>format</code> and <code>scale</code> are preferred. When possible, default values for elements are omitted for brevity's sake.</p> <p>Parameters:</p> Name Type Description Default <code>scalar</code> <code>bool | None</code> <p>If True, only scalar times will be accepted. If False, only vector times will be accepted. If None, no scalar constraints are enforced, unless <code>ndim</code> or <code>shape</code> are provided.</p> <code>None</code> <code>ndim</code> <code>int | None</code> <p>If given, the dimensionality of the time must match this value. Must be &gt;= 0.</p> <code>None</code> <code>shape</code> <code>Sequence[EllipsisType | int | range | slice | None] | None</code> <p>Shape specifier for the given time(s). See <code>NDArrayValidator</code> for a description of how this works.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import typing as ty\n&gt;&gt;&gt; import pydantic\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from astropy.time import Time\n&gt;&gt;&gt; from scientific_pydantic.astropy.time import (\n...     TimeAdapter,\n... )\n\n&gt;&gt;&gt; class Model(pydantic.BaseModel):\n...     t: ty.Annotated[Time, TimeAdapter()]\n\n&gt;&gt;&gt; Model(t=\"2026-03-01T19:50:00\")\nModel(t=&lt;Time object: scale='utc' format='isot' value=2026-03-01T19:50:00.000&gt;)\n</code></pre> Source code in <code>src/scientific_pydantic/astropy/time/time_adapter.py</code> <pre><code>class TimeAdapter:\n    \"\"\"Pydantic adapter for astropy.time.Time\n\n    Validation Options\n    ------------------\n    1. `Time` - Identity.\n    2. `Time`-like object - Any object that can be passed directly to the `Time`\n       constructor, such an ISO-8601 string or a `datetime.datetime` (or an\n       `ArrayLike` of these objects).\n    3. `Mapping` - A mapping of constructor arguments to `Time`. `val` and\n        `val2` can also be passed as `\"value\"`/`\"value2\"` keys.\n\n    JSON Serialization\n    ------------------\n    `Time`s are serialized in JSON as the `Mapping` option. If the `precision`\n    of the `Time` object is &gt; 6 (microsecond), then the format is converted to\n    `jd` and `jd1` and `jd2` are used for `\"value\"` and `\"value2\"`. Otherwise,\n    the `Time`'s `format` and `scale` are preferred. When possible, default\n    values for elements are omitted for brevity's sake.\n\n    Parameters\n    ----------\n    scalar\n        If True, only scalar times will be accepted. If False, only vector times\n        will be accepted. If None, no scalar constraints are enforced, unless\n        `ndim` or `shape` are provided.\n    ndim\n        If given, the dimensionality of the time must match this value. Must\n        be &gt;= 0.\n    shape\n        Shape specifier for the given time(s). See `NDArrayValidator` for a\n        description of how this works.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import typing as ty\n    &gt;&gt;&gt; import pydantic\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from astropy.time import Time\n    &gt;&gt;&gt; from scientific_pydantic.astropy.time import (\n    ...     TimeAdapter,\n    ... )  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; class Model(pydantic.BaseModel):\n    ...     t: ty.Annotated[Time, TimeAdapter()]  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; Model(t=\"2026-03-01T19:50:00\")\n    Model(t=&lt;Time object: scale='utc' format='isot' value=2026-03-01T19:50:00.000&gt;)\n    \"\"\"\n\n    def __init__(  # noqa: PLR0913\n        self,\n        *,\n        scalar: bool | None = None,\n        ndim: int | None = None,\n        shape: Sequence[types.EllipsisType | int | range | slice | None] | None = None,\n        ge: ty.Any = None,\n        gt: ty.Any = None,\n        le: ty.Any = None,\n        lt: ty.Any = None,\n    ) -&gt; None:\n\n        from scientific_pydantic.numpy.validators import (\n            validate_all_ge,\n            validate_all_gt,\n            validate_all_le,\n            validate_all_lt,\n        )\n\n        from ..validators import ArrayShapeValidator\n\n        @dataclasses.dataclass\n        class CtorValidators:\n            shape: ArrayShapeValidator\n            ge: ty.Callable[[Time], Time] | None = None\n            gt: ty.Callable[[Time], Time] | None = None\n            le: ty.Callable[[Time], Time] | None = None\n            lt: ty.Callable[[Time], Time] | None = None\n\n        validators: dict[str, ty.Callable] = {}\n        for bound, name, val in (\n            (gt, \"gt\", validate_all_gt),\n            (ge, \"ge\", validate_all_ge),\n            (lt, \"lt\", validate_all_lt),\n            (le, \"le\", validate_all_le),\n        ):\n            if bound is None:\n                continue\n            try:\n                bound_t = _validate_time(bound)\n            except ValueError as e:\n                msg = f\"while validating the {name} constraint:\\n{e}\"\n                raise pydantic.PydanticSchemaGenerationError(msg) from e\n\n            validators[name] = functools.partial(val, bound=bound_t)\n\n        self._validators = CtorValidators(\n            shape=ArrayShapeValidator(scalar=scalar, ndim=ndim, shape=shape),\n            **validators,\n        )\n\n    def __get_pydantic_core_schema__(\n        self,\n        _source_type: ty.Any,\n        _handler: GetCoreSchemaHandler,\n    ) -&gt; core_schema.CoreSchema:\n        \"\"\"Get the pydantic schema for this type\"\"\"\n        to_time = core_schema.no_info_plain_validator_function(_validate_time)\n        validators = core_schema.chain_schema(\n            [to_time]\n            + [\n                core_schema.no_info_plain_validator_function(func)\n                for field in dataclasses.fields(self._validators)\n                if (func := getattr(self._validators, field.name)) is not None\n            ]\n        )\n\n        return core_schema.json_or_python_schema(\n            json_schema=validators,\n            python_schema=validators,\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                _serialize_json,\n                when_used=\"json-unless-none\",\n            ),\n        )\n</code></pre>"},{"location":"api/scientific_pydantic/astropy/time/#scientific_pydantic.astropy.time.TimeAdapter.__get_pydantic_core_schema__","title":"<code>__get_pydantic_core_schema__(_source_type: ty.Any, _handler: GetCoreSchemaHandler) -&gt; core_schema.CoreSchema</code>","text":"<p>Get the pydantic schema for this type</p> Source code in <code>src/scientific_pydantic/astropy/time/time_adapter.py</code> <pre><code>def __get_pydantic_core_schema__(\n    self,\n    _source_type: ty.Any,\n    _handler: GetCoreSchemaHandler,\n) -&gt; core_schema.CoreSchema:\n    \"\"\"Get the pydantic schema for this type\"\"\"\n    to_time = core_schema.no_info_plain_validator_function(_validate_time)\n    validators = core_schema.chain_schema(\n        [to_time]\n        + [\n            core_schema.no_info_plain_validator_function(func)\n            for field in dataclasses.fields(self._validators)\n            if (func := getattr(self._validators, field.name)) is not None\n        ]\n    )\n\n    return core_schema.json_or_python_schema(\n        json_schema=validators,\n        python_schema=validators,\n        serialization=core_schema.plain_serializer_function_ser_schema(\n            _serialize_json,\n            when_used=\"json-unless-none\",\n        ),\n    )\n</code></pre>"},{"location":"api/scientific_pydantic/astropy/units/","title":"<code>units</code>","text":"<pre><code>import scientific_pydantic.astropy.units\n</code></pre>"},{"location":"api/scientific_pydantic/astropy/units/#scientific_pydantic.astropy.units","title":"<code>units</code>","text":"<p>Pydantic adapters for astropy.units</p> <p>The current supported types are:</p> <ul> <li><code>PhysicalType</code> -     <code>PhysicalTypeAdapter</code></li> <li><code>Quantity</code> -     <code>QuantityAdapter</code></li> <li><code>UnitBase</code> - <code>UnitAdapter</code></li> </ul>"},{"location":"api/scientific_pydantic/astropy/units/#scientific_pydantic.astropy.units.PhysicalTypeAdapter","title":"<code>PhysicalTypeAdapter</code>","text":"<p>A pydantic adapter for astropy.units.PhysicalType</p> Validation Options <ol> <li><code>PhysicalType</code> - Identity.</li> <li><code>str</code> - The name of the physical type (e.g. <code>\"length\"</code>, <code>\"mass\"</code>).     This is the form used for JSON encoding.</li> </ol> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import typing as ty\n&gt;&gt;&gt; import pydantic\n&gt;&gt;&gt; import astropy.units as u\n&gt;&gt;&gt; from scientific_pydantic.astropy.units import (\n...     PhysicalTypeAdapter,\n... )\n\n&gt;&gt;&gt; class Model(pydantic.BaseModel):\n...     pt: ty.Annotated[\n...         u.PhysicalType, PhysicalTypeAdapter()\n...     ]\n\n&gt;&gt;&gt; Model(pt=\"length\")\nModel(pt=PhysicalType('length'))\n</code></pre> Source code in <code>src/scientific_pydantic/astropy/units/physical_type.py</code> <pre><code>class PhysicalTypeAdapter:\n    \"\"\"A pydantic adapter for astropy.units.PhysicalType\n\n    Validation Options\n    ------------------\n    1. `PhysicalType` - Identity.\n    2. `str` - The name of the physical type (e.g. `\"length\"`, `\"mass\"`).\n        This is the form used for JSON encoding.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import typing as ty\n    &gt;&gt;&gt; import pydantic\n    &gt;&gt;&gt; import astropy.units as u\n    &gt;&gt;&gt; from scientific_pydantic.astropy.units import (\n    ...     PhysicalTypeAdapter,\n    ... )  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; class Model(pydantic.BaseModel):\n    ...     pt: ty.Annotated[\n    ...         u.PhysicalType, PhysicalTypeAdapter()\n    ...     ]  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; Model(pt=\"length\")\n    Model(pt=PhysicalType('length'))\n    \"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls,\n        source_type: ty.Any,\n        _handler: pydantic.GetCoreSchemaHandler,\n    ) -&gt; core_schema.CoreSchema:\n        \"\"\"Get the pydantic schema for this type\"\"\"\n        import astropy.units as u\n\n        from .validators import validate_physical_type\n\n        if source_type is not u.PhysicalType:\n            msg = (\n                \"PhysicalTypeAdapter is only usable with \"\n                f\"astropy.units.PhysicalType, not {source_type}.\"\n            )\n            raise pydantic.PydanticSchemaGenerationError(msg)\n\n        validator = core_schema.no_info_plain_validator_function(validate_physical_type)\n\n        return core_schema.json_or_python_schema(\n            json_schema=core_schema.chain_schema([core_schema.str_schema(), validator]),\n            python_schema=validator,\n            serialization=core_schema.to_string_ser_schema(\n                when_used=\"json-unless-none\"\n            ),\n        )\n\n    def __get_pydantic_json_schema__(\n        self,\n        core_schema_: core_schema.CoreSchema,\n        handler: pydantic.json_schema.GetJsonSchemaHandler,\n    ) -&gt; pydantic.json_schema.JsonSchemaValue:\n        \"\"\"Get the JSON schema for this type\"\"\"\n        del core_schema_\n\n        desc = \"An astropy PhysicalType expressed as a string.\"\n        return handler(core_schema.str_schema()) | {\n            \"description\": desc,\n            \"examples\": [\"length\", \"area\"],\n        }\n</code></pre>"},{"location":"api/scientific_pydantic/astropy/units/#scientific_pydantic.astropy.units.PhysicalTypeAdapter.__get_pydantic_core_schema__","title":"<code>__get_pydantic_core_schema__(source_type: ty.Any, _handler: pydantic.GetCoreSchemaHandler) -&gt; core_schema.CoreSchema</code>  <code>classmethod</code>","text":"<p>Get the pydantic schema for this type</p> Source code in <code>src/scientific_pydantic/astropy/units/physical_type.py</code> <pre><code>@classmethod\ndef __get_pydantic_core_schema__(\n    cls,\n    source_type: ty.Any,\n    _handler: pydantic.GetCoreSchemaHandler,\n) -&gt; core_schema.CoreSchema:\n    \"\"\"Get the pydantic schema for this type\"\"\"\n    import astropy.units as u\n\n    from .validators import validate_physical_type\n\n    if source_type is not u.PhysicalType:\n        msg = (\n            \"PhysicalTypeAdapter is only usable with \"\n            f\"astropy.units.PhysicalType, not {source_type}.\"\n        )\n        raise pydantic.PydanticSchemaGenerationError(msg)\n\n    validator = core_schema.no_info_plain_validator_function(validate_physical_type)\n\n    return core_schema.json_or_python_schema(\n        json_schema=core_schema.chain_schema([core_schema.str_schema(), validator]),\n        python_schema=validator,\n        serialization=core_schema.to_string_ser_schema(\n            when_used=\"json-unless-none\"\n        ),\n    )\n</code></pre>"},{"location":"api/scientific_pydantic/astropy/units/#scientific_pydantic.astropy.units.PhysicalTypeAdapter.__get_pydantic_json_schema__","title":"<code>__get_pydantic_json_schema__(core_schema_: core_schema.CoreSchema, handler: pydantic.json_schema.GetJsonSchemaHandler) -&gt; pydantic.json_schema.JsonSchemaValue</code>","text":"<p>Get the JSON schema for this type</p> Source code in <code>src/scientific_pydantic/astropy/units/physical_type.py</code> <pre><code>def __get_pydantic_json_schema__(\n    self,\n    core_schema_: core_schema.CoreSchema,\n    handler: pydantic.json_schema.GetJsonSchemaHandler,\n) -&gt; pydantic.json_schema.JsonSchemaValue:\n    \"\"\"Get the JSON schema for this type\"\"\"\n    del core_schema_\n\n    desc = \"An astropy PhysicalType expressed as a string.\"\n    return handler(core_schema.str_schema()) | {\n        \"description\": desc,\n        \"examples\": [\"length\", \"area\"],\n    }\n</code></pre>"},{"location":"api/scientific_pydantic/astropy/units/#scientific_pydantic.astropy.units.QuantityAdapter","title":"<code>QuantityAdapter</code>","text":"<p>Pydantic type adapter for astropy.units.Quantity</p> <p>This type supports a similar API to the numpy NDArray validator, but omits dtype, as astropy.units.Quantity's are always floating point.</p> Validation Options <ol> <li><code>Quantity</code> - Identity</li> <li><code>Quantity</code>-like object: Any object that can be passed to the constructor    of <code>Quantity</code>. For example, a string of the form \"5 m\" or a unitless    scalar/vector.</li> <li><code>Mapping</code> - A mapping with a <code>\"value\"</code> and optional (but required for any     non-unitless quantity) <code>\"unit\"</code> key. The <code>\"value\"</code> is any numeric     <code>ArrayLike</code> or scalar and the <code>\"unit\"</code> is anything that will validate     to a <code>UnitBase</code> via     UnitAdapater. This is     the form used for JSON serialization, with <code>\"value\"</code> being a JSON list     or number and <code>\"unit\"</code> being a string.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>equivalent_unit</code> <code>UnitBase | None</code> <p>If given, then quantities must have units equivalent to this.</p> <code>None</code> <code>equivalencies</code> <code>list[tuple] | None</code> <p>Optional list of astropy equivalency pairs (as returned by e.g. <code>astropy.units.spectral()</code>).  Passed verbatim to <code>UnitBase.is_equivalent</code>.</p> <code>None</code> <code>physical_type</code> <code>PhysicalType | str | Quantity | UnitBase | None</code> <p>If given, the quantity by have this physical type.</p> <code>None</code> <code>scalar</code> <code>bool | None</code> <p>If True, only scalar quantities will be accepted. If False, only vector quantities will be accepted. If None, no scalar constraints are enforced, unless <code>ndim</code> or <code>shape</code> are provided.</p> <code>None</code> <code>ndim</code> <code>int | None</code> <p>If given, the dimensionality of the quantity must match this value. Must be &gt;= 0.</p> <code>None</code> <code>shape</code> <code>Sequence[EllipsisType | int | range | slice | None] | None</code> <p>Shape specifier for the given array. See <code>NDArrayValidator</code> for a description of how this works.</p> <code>None</code> <code>gt</code> <code>ArrayLike | Quantity | None</code> <p>If given, all elements in the given quantity must be &gt; this value. If no units are provided, then <code>equivalent_unit</code> is used (if provided).</p> <code>None</code> <code>ge</code> <code>ArrayLike | Quantity | None</code> <p>If given, all elements in the given quantity must be &gt;= this value. If no units are provided, then <code>equivalent_unit</code> is used (if provided).</p> <code>None</code> <code>lt</code> <code>ArrayLike | Quantity | None</code> <p>If given, all elements in the given quantity must be &lt; this value. If no units are provided, then <code>equivalent_unit</code> is used (if provided).</p> <code>None</code> <code>le</code> <code>ArrayLike | Quantity | None</code> <p>If given, all elements in the given quantity must be &lt;= this value. If no units are provided, then <code>equivalent_unit</code> is used (if provided).</p> <code>None</code> <code>clip</code> <code>Sequence[ArrayLike | Quantity | None] | Quantity</code> <p>If given, a 2-element sequence of [min_clip, max_clip] to which to clip the values in the quantity. If no units are provided, then <code>equivalent_unit</code> is used (if provided).</p> <code>(None, None)</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import typing as ty\n&gt;&gt;&gt; import pydantic\n&gt;&gt;&gt; import astropy.units as u\n&gt;&gt;&gt; from scientific_pydantic.astropy.units import (\n...     QuantityAdapter,\n... )\n\n&gt;&gt;&gt; class Model(pydantic.BaseModel):\n...     q: ty.Annotated[\n...         u.Quantity, QuantityAdapter()\n...     ]\n\n&gt;&gt;&gt; Model(q=\"1.234 kg\")\nModel(q=&lt;Quantity 1.234 kg&gt;)\n</code></pre> Source code in <code>src/scientific_pydantic/astropy/units/quantity.py</code> <pre><code>class QuantityAdapter:\n    \"\"\"Pydantic type adapter for astropy.units.Quantity\n\n    This type supports a similar API to the numpy NDArray validator, but omits\n    dtype, as astropy.units.Quantity's are always floating point.\n\n    Validation Options\n    ------------------\n    1. `Quantity` - Identity\n    2. `Quantity`-like object: Any object that can be passed to the constructor\n       of `Quantity`. For example, a string of the form \"5 m\" or a unitless\n       scalar/vector.\n    3. `Mapping` - A mapping with a `\"value\"` and optional (but required for any\n        non-unitless quantity) `\"unit\"` key. The `\"value\"` is any numeric\n        `ArrayLike` or scalar and the `\"unit\"` is anything that will validate\n        to a `UnitBase` via\n        [UnitAdapater][scientific_pydantic.astropy.units.UnitAdapter]. This is\n        the form used for JSON serialization, with `\"value\"` being a JSON list\n        or number and `\"unit\"` being a string.\n\n    Parameters\n    ----------\n    equivalent_unit\n        If given, then quantities must have units equivalent to this.\n    equivalencies\n        Optional list of astropy equivalency pairs (as returned by e.g.\n        ``astropy.units.spectral()``).  Passed verbatim to\n        ``UnitBase.is_equivalent``.\n    physical_type\n        If given, the quantity by have this physical type.\n    scalar\n        If True, only scalar quantities will be accepted. If False, only vector\n        quantities will be accepted. If None, no scalar constraints are enforced,\n        unless `ndim` or `shape` are provided.\n    ndim\n        If given, the dimensionality of the quantity must match this value. Must\n        be &gt;= 0.\n    shape\n        Shape specifier for the given array. See `NDArrayValidator` for a\n        description of how this works.\n    gt\n        If given, all elements in the given quantity must be &gt; this value. If no\n        units are provided, then `equivalent_unit` is used (if provided).\n    ge\n        If given, all elements in the given quantity must be &gt;= this value. If no\n        units are provided, then `equivalent_unit` is used (if provided).\n    lt\n        If given, all elements in the given quantity must be &lt; this value. If no\n        units are provided, then `equivalent_unit` is used (if provided).\n    le\n        If given, all elements in the given quantity must be &lt;= this value. If no\n        units are provided, then `equivalent_unit` is used (if provided).\n    clip\n        If given, a 2-element sequence of [min_clip, max_clip] to which to clip\n        the values in the quantity. If no units are provided, then\n        `equivalent_unit` is used (if provided).\n\n    Examples\n    --------\n    &gt;&gt;&gt; import typing as ty\n    &gt;&gt;&gt; import pydantic\n    &gt;&gt;&gt; import astropy.units as u\n    &gt;&gt;&gt; from scientific_pydantic.astropy.units import (\n    ...     QuantityAdapter,\n    ... )  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; class Model(pydantic.BaseModel):\n    ...     q: ty.Annotated[\n    ...         u.Quantity, QuantityAdapter()\n    ...     ]  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; Model(q=\"1.234 kg\")\n    Model(q=&lt;Quantity 1.234 kg&gt;)\n    \"\"\"\n\n    def __init__(  # noqa: PLR0913\n        self,\n        equivalent_unit: u.UnitBase | None = None,\n        *,\n        equivalencies: list[tuple] | None = None,\n        physical_type: u.PhysicalType | str | u.Quantity | u.UnitBase | None = None,\n        scalar: bool | None = None,\n        ndim: int | None = None,\n        shape: Sequence[types.EllipsisType | int | range | slice | None] | None = None,\n        gt: ArrayLike | u.Quantity | None = None,\n        ge: ArrayLike | u.Quantity | None = None,\n        lt: ArrayLike | u.Quantity | None = None,\n        le: ArrayLike | u.Quantity | None = None,\n        clip: Sequence[ArrayLike | u.Quantity | None] | u.Quantity = (None, None),\n        serialize_as_unit: u.UnitBase | None = None,\n    ) -&gt; None:\n        import astropy.units as u\n        import numpy as np\n\n        from scientific_pydantic.numpy.validators import (\n            validate_all_ge,\n            validate_all_gt,\n            validate_all_le,\n            validate_all_lt,\n        )\n\n        from ..validators import ArrayShapeValidator\n        from .validators import (\n            EquivalencyValidator,\n            PhysicalTypeValidator,\n        )\n\n        self._serialize_as_unit = serialize_as_unit\n\n        @dataclasses.dataclass\n        class CtorValidators:\n            shape: ArrayShapeValidator\n            equivalency: EquivalencyValidator | None = None\n            physical_type: PhysicalTypeValidator | None = None\n            ge: ty.Callable[[u.Quantity], u.Quantity] | None = None\n            gt: ty.Callable[[u.Quantity], u.Quantity] | None = None\n            le: ty.Callable[[u.Quantity], u.Quantity] | None = None\n            lt: ty.Callable[[u.Quantity], u.Quantity] | None = None\n            clip: ty.Callable[[u.Quantity], u.Quantity] | None = None\n\n        validators: dict[str, ty.Callable[[u.Quantity], u.Quantity]] = {}\n\n        def apply_unit_to_bound(\n            x: ArrayLike | u.Quantity | None, name: str\n        ) -&gt; u.Quantity | None:\n            if x is None:\n                return None\n            if isinstance(x, u.Quantity):\n                return x\n            if equivalent_unit is not None:\n                return x &lt;&lt; equivalent_unit\n            msg = (\n                f'If equivalent_unit is not defined, then \"{name}\" must be '\n                \"a Quantity if given\"\n            )\n            raise PydanticSchemaGenerationError(msg)\n\n        for bound, name, val in (\n            (gt, \"gt\", validate_all_gt),\n            (ge, \"ge\", validate_all_ge),\n            (lt, \"lt\", validate_all_lt),\n            (le, \"le\", validate_all_le),\n        ):\n            bound_quant = apply_unit_to_bound(bound, name)\n            if bound_quant is not None:\n                validators[name] = functools.partial(val, bound=bound_quant)\n\n        if len(clip) != 2:  # noqa: PLR2004\n            msg = f\"clip must be a sequence of size 2, was {len(clip)}\"\n            raise PydanticSchemaGenerationError(msg)\n\n        clip = (\n            apply_unit_to_bound(clip[0], \"clip[0]\"),\n            apply_unit_to_bound(clip[1], \"clip[1]\"),\n        )\n\n        def clip_val(q: u.Quantity) -&gt; u.Quantity:\n            if clip[0] is not None or clip[1] is not None:\n                return np.clip(q, clip[0], clip[1])  # type: ignore[bad-return]\n            return q\n\n        validators[\"clip\"] = clip_val\n\n        self._validators = CtorValidators(\n            equivalency=EquivalencyValidator(\n                equivalent_unit, equivalencies=equivalencies\n            )\n            if equivalent_unit is not None\n            else None,\n            physical_type=PhysicalTypeValidator(validate_physical_type(physical_type))\n            if physical_type is not None\n            else None,\n            shape=ArrayShapeValidator(scalar=scalar, ndim=ndim, shape=shape),\n            **validators,  # type: ignore[bad-argument-type]\n        )\n\n    def __get_pydantic_core_schema__(\n        self,\n        _source_type: ty.Any,\n        _handler: GetCoreSchemaHandler,\n    ) -&gt; core_schema.CoreSchema:\n        \"\"\"Get the pydantic schema for this type\"\"\"\n        validators = [\n            core_schema.no_info_plain_validator_function(func)\n            for field in dataclasses.fields(self._validators)\n            if (func := getattr(self._validators, field.name)) is not None\n        ]\n\n        return core_schema.json_or_python_schema(\n            json_schema=core_schema.chain_schema(\n                [\n                    core_schema.no_info_plain_validator_function(_validate_quantity),\n                    *validators,\n                ],\n            ),\n            python_schema=core_schema.chain_schema(\n                [\n                    core_schema.no_info_plain_validator_function(_validate_quantity),\n                    *validators,\n                ],\n            ),\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                functools.partial(\n                    _serialize, serialize_as_unit=self._serialize_as_unit\n                ),\n                info_arg=True,\n                when_used=\"unless-none\",\n            ),\n        )\n\n    @classmethod\n    def __get_pydantic_json_schema__(\n        cls,\n        _core_schema: core_schema.CoreSchema,\n        handler: pydantic.GetJsonSchemaHandler,\n    ) -&gt; JsonSchemaValue:\n        \"\"\"Generate JSON schema for the ndarray field\"\"\"\n        schema = handler(core_schema.any_schema())\n        schema[\"description\"] = \"An encoding of an astropy.units.Quantity\"\n        return schema\n</code></pre>"},{"location":"api/scientific_pydantic/astropy/units/#scientific_pydantic.astropy.units.QuantityAdapter.__get_pydantic_core_schema__","title":"<code>__get_pydantic_core_schema__(_source_type: ty.Any, _handler: GetCoreSchemaHandler) -&gt; core_schema.CoreSchema</code>","text":"<p>Get the pydantic schema for this type</p> Source code in <code>src/scientific_pydantic/astropy/units/quantity.py</code> <pre><code>def __get_pydantic_core_schema__(\n    self,\n    _source_type: ty.Any,\n    _handler: GetCoreSchemaHandler,\n) -&gt; core_schema.CoreSchema:\n    \"\"\"Get the pydantic schema for this type\"\"\"\n    validators = [\n        core_schema.no_info_plain_validator_function(func)\n        for field in dataclasses.fields(self._validators)\n        if (func := getattr(self._validators, field.name)) is not None\n    ]\n\n    return core_schema.json_or_python_schema(\n        json_schema=core_schema.chain_schema(\n            [\n                core_schema.no_info_plain_validator_function(_validate_quantity),\n                *validators,\n            ],\n        ),\n        python_schema=core_schema.chain_schema(\n            [\n                core_schema.no_info_plain_validator_function(_validate_quantity),\n                *validators,\n            ],\n        ),\n        serialization=core_schema.plain_serializer_function_ser_schema(\n            functools.partial(\n                _serialize, serialize_as_unit=self._serialize_as_unit\n            ),\n            info_arg=True,\n            when_used=\"unless-none\",\n        ),\n    )\n</code></pre>"},{"location":"api/scientific_pydantic/astropy/units/#scientific_pydantic.astropy.units.QuantityAdapter.__get_pydantic_json_schema__","title":"<code>__get_pydantic_json_schema__(_core_schema: core_schema.CoreSchema, handler: pydantic.GetJsonSchemaHandler) -&gt; JsonSchemaValue</code>  <code>classmethod</code>","text":"<p>Generate JSON schema for the ndarray field</p> Source code in <code>src/scientific_pydantic/astropy/units/quantity.py</code> <pre><code>@classmethod\ndef __get_pydantic_json_schema__(\n    cls,\n    _core_schema: core_schema.CoreSchema,\n    handler: pydantic.GetJsonSchemaHandler,\n) -&gt; JsonSchemaValue:\n    \"\"\"Generate JSON schema for the ndarray field\"\"\"\n    schema = handler(core_schema.any_schema())\n    schema[\"description\"] = \"An encoding of an astropy.units.Quantity\"\n    return schema\n</code></pre>"},{"location":"api/scientific_pydantic/astropy/units/#scientific_pydantic.astropy.units.UnitAdapter","title":"<code>UnitAdapter</code>","text":"<p>A <code>pydantic</code> adapter for <code>astropy.units.UnitBase</code></p> Validation Options <ol> <li><code>UnitBase</code> - Identity.</li> <li><code>str</code> - A string encoding of units that can be passed to the constructor        of <code>Unit</code> (e.g. <code>\"kg m / s2\"</code>). This is the form used for JSON        encoding.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>equivalent_unit</code> <code>UnitBase | str | None</code> <p>If given, validated values must be equivalent to this unit.</p> <code>None</code> <code>equivalencies</code> <code>list[tuple] | None</code> <p>Optional list of astropy equivalency pairs (as returned by e.g. <code>astropy.units.spectral()</code>).  Passed verbatim to <code>UnitBase.is_equivalent</code>.</p> <code>None</code> <code>physical_type</code> <code>PhysicalType | str | Quantity | UnitBase | None</code> <p>If given, the unit by have this physical type</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import typing as ty\n&gt;&gt;&gt; import pydantic\n&gt;&gt;&gt; import astropy.units as u\n&gt;&gt;&gt; from scientific_pydantic.astropy.units import (\n...     UnitAdapter,\n... )\n\n&gt;&gt;&gt; class Model(pydantic.BaseModel):\n...     u: ty.Annotated[u.UnitBase, UnitAdapter()]\n\n&gt;&gt;&gt; Model(u=\"kg m / s2\")\nModel(u=Unit(\"kg m / s2\"))\n</code></pre> Source code in <code>src/scientific_pydantic/astropy/units/unit.py</code> <pre><code>class UnitAdapter:\n    \"\"\"A `pydantic` adapter for `astropy.units.UnitBase`\n\n    Validation Options\n    ------------------\n    1. `UnitBase` - Identity.\n    2. `str` - A string encoding of units that can be passed to the constructor\n           of `Unit` (e.g. `\"kg m / s2\"`). This is the form used for JSON\n           encoding.\n\n    Parameters\n    ----------\n    equivalent_unit\n        If given, validated values must be equivalent to this unit.\n    equivalencies\n        Optional list of astropy equivalency pairs (as returned by e.g.\n        ``astropy.units.spectral()``).  Passed verbatim to\n        ``UnitBase.is_equivalent``.\n    physical_type\n        If given, the unit by have this physical type\n\n    Examples\n    --------\n    &gt;&gt;&gt; import typing as ty\n    &gt;&gt;&gt; import pydantic\n    &gt;&gt;&gt; import astropy.units as u\n    &gt;&gt;&gt; from scientific_pydantic.astropy.units import (\n    ...     UnitAdapter,\n    ... )  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; class Model(pydantic.BaseModel):\n    ...     u: ty.Annotated[u.UnitBase, UnitAdapter()]  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; Model(u=\"kg m / s2\")\n    Model(u=Unit(\"kg m / s2\"))\n    \"\"\"\n\n    def __init__(\n        self,\n        equivalent_unit: u.UnitBase | str | None = None,\n        *,\n        equivalencies: list[tuple] | None = None,\n        physical_type: u.PhysicalType | str | u.Quantity | u.UnitBase | None = None,\n    ) -&gt; None:\n        from .validators import (\n            EquivalencyValidator,\n            PhysicalTypeValidator,\n            validate_physical_type,\n        )\n\n        @dataclasses.dataclass\n        class Validators:\n            equivalency: EquivalencyValidator | None = None\n            physical_type: PhysicalTypeValidator | None = None\n\n        validators: dict[str, ty.Any] = {}\n\n        if equivalent_unit is not None:\n            validators[\"equivalency\"] = EquivalencyValidator(\n                equivalent_unit, equivalencies=equivalencies\n            )\n\n        if physical_type is not None:\n            validators[\"physical_type\"] = PhysicalTypeValidator(\n                validate_physical_type(physical_type)\n            )\n        self._validators = Validators(**validators)\n\n    @property\n    def equivalent_unit(self) -&gt; u.UnitBase | None:\n        \"\"\"If non-None, validated units must be equivalent to this unit\"\"\"\n        val = self._validators.equivalency\n        return val.equivalent_unit if val is not None else None\n\n    @property\n    def equivalencies(self) -&gt; list[tuple] | None:\n        \"\"\"Custom equivalencies for the equivalency check\"\"\"\n        val = self._validators.equivalency\n        return val.equivalencies if val is not None else None\n\n    @property\n    def physical_type(self) -&gt; u.PhysicalType | None:\n        \"\"\"If non-None, validated unit must be of this physical type\"\"\"\n        val = self._validators.physical_type\n        return val.physical_type if val is not None else None\n\n    def __get_pydantic_core_schema__(\n        self,\n        source_type: ty.Any,\n        _handler: pydantic.GetCoreSchemaHandler,\n    ) -&gt; core_schema.CoreSchema:\n        \"\"\"Get the pydantic schema for this type\"\"\"\n        import astropy.units as u\n\n        from .validators import validate_unit\n\n        if source_type is not u.UnitBase:\n            msg = (\n                \"UnitAdapter is only usable with \"\n                f\"astropy.units.UnitBase, not {source_type}.\"\n            )\n            raise pydantic.PydanticSchemaGenerationError(msg)\n\n        validators: list[core_schema.CoreSchema] = [\n            core_schema.no_info_plain_validator_function(validate_unit)\n        ]\n        if (equiv_val := self._validators.equivalency) is not None:\n            validators.append(core_schema.no_info_plain_validator_function(equiv_val))\n        if (pt_val := self._validators.physical_type) is not None:\n            validators.append(core_schema.no_info_plain_validator_function(pt_val))\n\n        return core_schema.json_or_python_schema(\n            json_schema=core_schema.chain_schema(\n                [core_schema.str_schema(), *validators]\n            ),\n            python_schema=core_schema.chain_schema(validators),\n            serialization=core_schema.to_string_ser_schema(),\n        )\n\n    def __get_pydantic_json_schema__(\n        self,\n        core_schema_: core_schema.CoreSchema,\n        handler: pydantic.json_schema.GetJsonSchemaHandler,\n    ) -&gt; pydantic.json_schema.JsonSchemaValue:\n        \"\"\"Get the JSON schema for this type\"\"\"\n        del core_schema_\n\n        desc = \"An astropy unit expressed as a string.\"\n        if self.equivalent_unit is not None:\n            equiv_hint = \"\"\n            if self.equivalencies is not None:\n                equiv_hint = (\n                    \" (with custom equivalencies: \"\n                    + \", \".join(f\"{x[0]} &lt;-&gt; {x[1]}\" for x in self.equivalencies)\n                    + \")\"\n                )\n            desc += f' Must be equivalent to \"{self.equivalent_unit}\"{equiv_hint}.'\n        if self.physical_type is not None:\n            desc += f' Must be of type \"{self.physical_type!s}\".'\n\n        return handler(core_schema.str_schema()) | {\n            \"description\": desc,\n            \"examples\": [\"m / s\", \"km / h\", \"kg\", \"deg\", \"J / (kg K)\"]\n            if self.equivalent_unit is None\n            else [str(self.equivalent_unit)],\n        }\n</code></pre>"},{"location":"api/scientific_pydantic/astropy/units/#scientific_pydantic.astropy.units.UnitAdapter.equivalent_unit","title":"<code>equivalent_unit: u.UnitBase | None</code>  <code>property</code>","text":"<p>If non-None, validated units must be equivalent to this unit</p>"},{"location":"api/scientific_pydantic/astropy/units/#scientific_pydantic.astropy.units.UnitAdapter.equivalencies","title":"<code>equivalencies: list[tuple] | None</code>  <code>property</code>","text":"<p>Custom equivalencies for the equivalency check</p>"},{"location":"api/scientific_pydantic/astropy/units/#scientific_pydantic.astropy.units.UnitAdapter.physical_type","title":"<code>physical_type: u.PhysicalType | None</code>  <code>property</code>","text":"<p>If non-None, validated unit must be of this physical type</p>"},{"location":"api/scientific_pydantic/astropy/units/#scientific_pydantic.astropy.units.UnitAdapter.__get_pydantic_core_schema__","title":"<code>__get_pydantic_core_schema__(source_type: ty.Any, _handler: pydantic.GetCoreSchemaHandler) -&gt; core_schema.CoreSchema</code>","text":"<p>Get the pydantic schema for this type</p> Source code in <code>src/scientific_pydantic/astropy/units/unit.py</code> <pre><code>def __get_pydantic_core_schema__(\n    self,\n    source_type: ty.Any,\n    _handler: pydantic.GetCoreSchemaHandler,\n) -&gt; core_schema.CoreSchema:\n    \"\"\"Get the pydantic schema for this type\"\"\"\n    import astropy.units as u\n\n    from .validators import validate_unit\n\n    if source_type is not u.UnitBase:\n        msg = (\n            \"UnitAdapter is only usable with \"\n            f\"astropy.units.UnitBase, not {source_type}.\"\n        )\n        raise pydantic.PydanticSchemaGenerationError(msg)\n\n    validators: list[core_schema.CoreSchema] = [\n        core_schema.no_info_plain_validator_function(validate_unit)\n    ]\n    if (equiv_val := self._validators.equivalency) is not None:\n        validators.append(core_schema.no_info_plain_validator_function(equiv_val))\n    if (pt_val := self._validators.physical_type) is not None:\n        validators.append(core_schema.no_info_plain_validator_function(pt_val))\n\n    return core_schema.json_or_python_schema(\n        json_schema=core_schema.chain_schema(\n            [core_schema.str_schema(), *validators]\n        ),\n        python_schema=core_schema.chain_schema(validators),\n        serialization=core_schema.to_string_ser_schema(),\n    )\n</code></pre>"},{"location":"api/scientific_pydantic/astropy/units/#scientific_pydantic.astropy.units.UnitAdapter.__get_pydantic_json_schema__","title":"<code>__get_pydantic_json_schema__(core_schema_: core_schema.CoreSchema, handler: pydantic.json_schema.GetJsonSchemaHandler) -&gt; pydantic.json_schema.JsonSchemaValue</code>","text":"<p>Get the JSON schema for this type</p> Source code in <code>src/scientific_pydantic/astropy/units/unit.py</code> <pre><code>def __get_pydantic_json_schema__(\n    self,\n    core_schema_: core_schema.CoreSchema,\n    handler: pydantic.json_schema.GetJsonSchemaHandler,\n) -&gt; pydantic.json_schema.JsonSchemaValue:\n    \"\"\"Get the JSON schema for this type\"\"\"\n    del core_schema_\n\n    desc = \"An astropy unit expressed as a string.\"\n    if self.equivalent_unit is not None:\n        equiv_hint = \"\"\n        if self.equivalencies is not None:\n            equiv_hint = (\n                \" (with custom equivalencies: \"\n                + \", \".join(f\"{x[0]} &lt;-&gt; {x[1]}\" for x in self.equivalencies)\n                + \")\"\n            )\n        desc += f' Must be equivalent to \"{self.equivalent_unit}\"{equiv_hint}.'\n    if self.physical_type is not None:\n        desc += f' Must be of type \"{self.physical_type!s}\".'\n\n    return handler(core_schema.str_schema()) | {\n        \"description\": desc,\n        \"examples\": [\"m / s\", \"km / h\", \"kg\", \"deg\", \"J / (kg K)\"]\n        if self.equivalent_unit is None\n        else [str(self.equivalent_unit)],\n    }\n</code></pre>"},{"location":"api/scientific_pydantic/numpy/","title":"<code>numpy</code>","text":"<pre><code>import scientific_pydantic.numpy\n</code></pre>"},{"location":"api/scientific_pydantic/numpy/#scientific_pydantic.numpy","title":"<code>numpy</code>","text":"<p>Pydantic adapters for numpy types</p> <p>The current supported types are:</p> <ul> <li><code>dtype</code> - DTypeAdapter</li> <li><code>ndarray</code> - NDArrayAdapter</li> </ul>"},{"location":"api/scientific_pydantic/numpy/#scientific_pydantic.numpy.DTypeAdapter","title":"<code>DTypeAdapter</code>","text":"<p>Pydantic adapter for numpy.dtype</p> Validation Options <ol> <li><code>dtype</code>: Identity.</li> <li><code>dtype</code>-like object: Anything that can be converted to a numpy <code>dtype</code>    object via <code>dtype.__init__</code>. This notably includes the string    representations (e.g. '&lt;f8', '|i4') or Python/numpy numeric types.</li> </ol> JSON Serialization <p><code>dtype</code>'s are serialized to JSON via the <code>.str</code> property.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pydantic\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from scientific_pydantic.numpy import (\n...     DTypeAdapter,\n... )\n\n&gt;&gt;&gt; class Model(pydantic.BaseModel):\n...     dt: ty.Annotated[np.dtype, DTypeAdapter()]\n\n&gt;&gt;&gt; Model(dt=\"|i4\")\nModel(dt=dtype('int32'))\n&gt;&gt;&gt; Model(dt=float)\nModel(dt=dtype('float64'))\n&gt;&gt;&gt; Model(dt=np.float64)\nModel(dt=dtype('float64'))\n</code></pre> Source code in <code>src/scientific_pydantic/numpy/dtype_adapter.py</code> <pre><code>class DTypeAdapter:\n    \"\"\"Pydantic adapter for numpy.dtype\n\n    Validation Options\n    ------------------\n    1. `dtype`: Identity.\n    2. `dtype`-like object: Anything that can be converted to a numpy `dtype`\n       object via `dtype.__init__`. This notably includes the string\n       representations (e.g. '&lt;f8', '|i4') or Python/numpy numeric types.\n\n    JSON Serialization\n    ------------------\n    `dtype`'s are serialized to JSON via the `.str` property.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pydantic\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from scientific_pydantic.numpy import (\n    ...     DTypeAdapter,\n    ... )  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; class Model(pydantic.BaseModel):\n    ...     dt: ty.Annotated[np.dtype, DTypeAdapter()]  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; Model(dt=\"|i4\")\n    Model(dt=dtype('int32'))\n    &gt;&gt;&gt; Model(dt=float)\n    Model(dt=dtype('float64'))\n    &gt;&gt;&gt; Model(dt=np.float64)\n    Model(dt=dtype('float64'))\n    \"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls,\n        _source_type: type[ty.Any],\n        _handler: pydantic.GetCoreSchemaHandler,\n    ) -&gt; core_schema.CoreSchema:\n        \"\"\"Get the pydantic schema for this type\"\"\"\n        return core_schema.no_info_plain_validator_function(\n            cls._validate,\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                cls._serialize,\n            ),\n        )\n\n    @staticmethod\n    def _validate(value: ty.Any) -&gt; \"np.dtype\":\n        import numpy as np\n\n        if isinstance(value, np.dtype):\n            return value\n\n        try:\n            return np.dtype(value)\n        except Exception as exc:\n            msg = f\"Invalid numpy dtype: {value!r}\"\n            raise ValueError(msg) from exc\n\n    @staticmethod\n    def _serialize(value: \"np.dtype\") -&gt; str:\n        return value.str\n\n    def __get_pydantic_json_schema__(\n        self,\n        _core_schema: core_schema.CoreSchema,\n        _handler: pydantic.GetJsonSchemaHandler,\n    ) -&gt; JsonSchemaValue:\n        \"\"\"Generate JSON schema for the ndarray field\"\"\"\n        json_schema = ty.cast(\"dict\", core_schema.str_schema())\n        json_schema[\"description\"] = \"NumPy dtype\"\n        return ty.cast(\"JsonSchemaValue\", json_schema)\n</code></pre>"},{"location":"api/scientific_pydantic/numpy/#scientific_pydantic.numpy.DTypeAdapter.__get_pydantic_core_schema__","title":"<code>__get_pydantic_core_schema__(_source_type: type[ty.Any], _handler: pydantic.GetCoreSchemaHandler) -&gt; core_schema.CoreSchema</code>  <code>classmethod</code>","text":"<p>Get the pydantic schema for this type</p> Source code in <code>src/scientific_pydantic/numpy/dtype_adapter.py</code> <pre><code>@classmethod\ndef __get_pydantic_core_schema__(\n    cls,\n    _source_type: type[ty.Any],\n    _handler: pydantic.GetCoreSchemaHandler,\n) -&gt; core_schema.CoreSchema:\n    \"\"\"Get the pydantic schema for this type\"\"\"\n    return core_schema.no_info_plain_validator_function(\n        cls._validate,\n        serialization=core_schema.plain_serializer_function_ser_schema(\n            cls._serialize,\n        ),\n    )\n</code></pre>"},{"location":"api/scientific_pydantic/numpy/#scientific_pydantic.numpy.DTypeAdapter.__get_pydantic_json_schema__","title":"<code>__get_pydantic_json_schema__(_core_schema: core_schema.CoreSchema, _handler: pydantic.GetJsonSchemaHandler) -&gt; JsonSchemaValue</code>","text":"<p>Generate JSON schema for the ndarray field</p> Source code in <code>src/scientific_pydantic/numpy/dtype_adapter.py</code> <pre><code>def __get_pydantic_json_schema__(\n    self,\n    _core_schema: core_schema.CoreSchema,\n    _handler: pydantic.GetJsonSchemaHandler,\n) -&gt; JsonSchemaValue:\n    \"\"\"Generate JSON schema for the ndarray field\"\"\"\n    json_schema = ty.cast(\"dict\", core_schema.str_schema())\n    json_schema[\"description\"] = \"NumPy dtype\"\n    return ty.cast(\"JsonSchemaValue\", json_schema)\n</code></pre>"},{"location":"api/scientific_pydantic/numpy/#scientific_pydantic.numpy.NDArrayAdapter","title":"<code>NDArrayAdapter</code>","text":"<p>Pydantic type adapter for numpy <code>ndarray</code>s with validation constraints.</p> Validation Options <ol> <li><code>ndarray</code> - Identity</li> <li><code>ArrayLike</code> - Any object that can be converted to an <code>ndarray</code> via    <code>np.asarray</code>.</li> </ol> Shape Specifiers <p>Shape specifiers for arrays are a sequence of entries, which support the options:</p> <ul> <li><code>Ellipsis</code>/<code>...</code> - A wildcard match that matches any number of dimensions   with any size. Multiple can be used in a shape specifier.</li> <li><code>int</code> - The corresponding dimension of the array must have exactly this   size.</li> <li><code>range</code> - The corresponding dimension of the array must have a size that   is in this <code>range</code>.</li> <li><code>slice</code> - The corresponding dimension of the array must have a size that   is in this <code>slice</code>. A <code>None</code> in the start or stop of the <code>slice</code> indicates   that there is no lower or upper bound, respectively, for the dimension   size.</li> <li><code>None</code> - The corresponding dimension must exist, but no constraint is   applied to the size.</li> </ul> <p>For instance, a shape specifier of: <pre><code>(..., 3, None, range(1, 3), slice(3, None))\n</code></pre> would indicate the array must have at least 4 dimensions, where the last 4 dimensions must be of size 4, anything, 1 or 2, and at least 3.</p> JSON Serialization <p><code>ndarray</code>s are encoded in JSON via nested list, which are obtained by calling <code>.tolist()</code> on the <code>ndarray</code>.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>type | dtype | str | None</code> <p>If given, the array will be coerced into this data type via <code>.astype()</code>.</p> <code>None</code> <code>ndim</code> <code>int | None</code> <p>If given, the array must have this dimensionality.</p> <code>None</code> <code>shape</code> <code>Sequence[EllipsisType | int | range | slice | None] | None</code> <p>If given a shape specifier for the array.</p> <code>None</code> <code>gt</code> <code>float | None</code> <p>If given, all elements in the array must be <code>&gt;</code> this value.</p> <code>None</code> <code>ge</code> <code>float | None</code> <p>If given, all elements in the array must be <code>&gt;=</code> this value.</p> <code>None</code> <code>lt</code> <code>float | None</code> <p>If given, all elements in the array must be <code>&lt;</code> this value.</p> <code>None</code> <code>le</code> <code>float | None</code> <p>If given, all elements in the array must be <code>&lt;=</code> this value.</p> <code>None</code> <code>clip</code> <code>tuple[float | None, float | None]</code> <p>If not <code>(None, None)</code>, the array will be passed through <code>numpy.clip(array, clip[0], clip[1])</code> to bound the values.</p> <code>(None, None)</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import typing as ty\n&gt;&gt;&gt; import pydantic\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from scientific_pydantic.numpy import (\n...     NDArrayAdapter,\n... )\n\n&gt;&gt;&gt; class Model(pydantic.BaseModel):\n...     a: ty.Annotated[\n...         np.ndarray, NDArrayAdapter()\n...     ]\n\n&gt;&gt;&gt; Model(a=[[1, 2], [3, 4]])\nModel(a=array([[1, 2],\n       [3, 4]]))\n</code></pre> Source code in <code>src/scientific_pydantic/numpy/ndarray_adapter.py</code> <pre><code>class NDArrayAdapter:\n    \"\"\"Pydantic type adapter for numpy `ndarray`s with validation constraints.\n\n    Validation Options\n    ------------------\n    1. `ndarray` - Identity\n    2. `ArrayLike` - Any object that can be converted to an `ndarray` via\n       [`np.asarray`](https://numpy.org/doc/stable/reference/generated/numpy.asarray.html).\n\n    Shape Specifiers\n    ----------------\n    Shape specifiers for arrays are a sequence of entries, which support the\n    options:\n\n    - `Ellipsis`/`...` - A wildcard match that matches any number of dimensions\n      with any size. Multiple can be used in a shape specifier.\n    - `int` - The corresponding dimension of the array must have exactly this\n      size.\n    - `range` - The corresponding dimension of the array must have a size that\n      is in this `range`.\n    - `slice` - The corresponding dimension of the array must have a size that\n      is in this `slice`. A `None` in the start or stop of the `slice` indicates\n      that there is no lower or upper bound, respectively, for the dimension\n      size.\n    - `None` - The corresponding dimension must exist, but no constraint is\n      applied to the size.\n\n    For instance, a shape specifier of:\n    ```python\n    (..., 3, None, range(1, 3), slice(3, None))\n    ```\n    would indicate the array must have at least 4 dimensions, where the last 4\n    dimensions must be of size 4, anything, 1 or 2, and at least 3.\n\n    JSON Serialization\n    ------------------\n    `ndarray`s are encoded in JSON via nested list, which are obtained by\n    calling `.tolist()` on the `ndarray`.\n\n    Parameters\n    ----------\n    dtype\n        If given, the array will be coerced into this data type via `.astype()`.\n    ndim\n        If given, the array must have this dimensionality.\n    shape\n        If given a shape specifier for the array.\n    gt\n        If given, all elements in the array must be `&gt;` this value.\n    ge\n        If given, all elements in the array must be `&gt;=` this value.\n    lt\n        If given, all elements in the array must be `&lt;` this value.\n    le\n        If given, all elements in the array must be `&lt;=` this value.\n    clip\n        If not `(None, None)`, the array will be passed through\n        `numpy.clip(array, clip[0], clip[1])` to bound the values.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import typing as ty\n    &gt;&gt;&gt; import pydantic\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from scientific_pydantic.numpy import (\n    ...     NDArrayAdapter,\n    ... )  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; class Model(pydantic.BaseModel):\n    ...     a: ty.Annotated[\n    ...         np.ndarray, NDArrayAdapter()\n    ...     ]  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; Model(a=[[1, 2], [3, 4]])\n    Model(a=array([[1, 2],\n           [3, 4]]))\n    \"\"\"\n\n    def __init__(  # noqa: PLR0913\n        self,\n        *,\n        dtype: \"type | np.dtype | str | None\" = None,\n        ndim: int | None = None,\n        shape: Sequence[types.EllipsisType | int | range | slice | None] | None = None,\n        gt: float | None = None,\n        ge: float | None = None,\n        lt: float | None = None,\n        le: float | None = None,\n        clip: tuple[float | None, float | None] = (None, None),\n    ) -&gt; None:\n        from .validators import NDArrayValidator\n\n        self._validator = NDArrayValidator.from_kwargs(\n            dtype=dtype,\n            ndim=ndim,\n            shape=shape,\n            gt=gt,\n            ge=ge,\n            lt=lt,\n            le=le,\n            clip=clip,\n        )\n\n    def __get_pydantic_core_schema__(\n        self,\n        _source_type: ty.Any,\n        _handler: pydantic.GetCoreSchemaHandler,\n    ) -&gt; core_schema.CoreSchema:\n        \"\"\"Get the pydantic schema for an NDArray\"\"\"\n        import numpy as np\n\n        def validate(value: ty.Any) -&gt; np.typing.NDArray:\n            return self._validator(value)\n\n        def serialize(value: np.typing.NDArray) -&gt; list:\n            \"\"\"Serialize ndarray to nested lists for JSON\"\"\"\n            return value.tolist()\n\n        python_schema = core_schema.no_info_after_validator_function(\n            validate,\n            core_schema.any_schema(),\n        )\n\n        return core_schema.json_or_python_schema(\n            json_schema=core_schema.chain_schema(\n                [\n                    core_schema.any_schema(),\n                    core_schema.no_info_after_validator_function(\n                        validate,\n                        core_schema.any_schema(),\n                    ),\n                ],\n            ),\n            python_schema=python_schema,\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                serialize,\n                info_arg=False,\n                return_schema=core_schema.any_schema(),\n            ),\n        )\n\n    def __get_pydantic_json_schema__(  # noqa: C901\n        self,\n        _core_schema: core_schema.CoreSchema,\n        _handler: pydantic.GetJsonSchemaHandler,\n    ) -&gt; JsonSchemaValue:\n        \"\"\"Generate JSON schema for the ndarray field\"\"\"\n        json_schema: dict[str, ty.Any] = {\"type\": \"array\"}\n\n        # Add description of constraints\n        constraints = []\n        if self._validator.dtype is not None:\n            constraints.append(f\"dtype: {self._validator.dtype.dtype}\")\n\n        ndim = self._validator.ndim.ndim if self._validator.ndim is not None else None\n        if ndim is not None:\n            constraints.append(f\"{ndim}D array\")\n        if self._validator.shape is not None:\n            shape_desc = \"x\".join(\n                str(s) if s is not None else \"?\" for s in self._validator.shape.shape\n            )\n            constraints.append(f\"shape: ({shape_desc})\")\n        if self._validator.ge is not None:\n            constraints.append(f\"values &gt;= {self._validator.ge.ge}\")\n        if self._validator.le is not None:\n            constraints.append(f\"values &lt;= {self._validator.le.le}\")\n        if self._validator.gt is not None:\n            constraints.append(f\"values &gt; {self._validator.gt.gt}\")\n        if self._validator.lt is not None:\n            constraints.append(f\"values &lt; {self._validator.lt.lt}\")\n        if self._validator.clip is not None:\n            constraints.append(\n                f\"clipped to [{self._validator.clip.clip[0]}, \"\n                f\"{self._validator.clip.clip[1]}]\",\n            )\n\n        if constraints:\n            json_schema[\"description\"] = \"NumPy array: \" + \", \".join(constraints)\n\n        # Add items constraint based on ndim\n        if ndim is not None and ndim &lt;= 1:\n            json_schema[\"items\"] = {\"type\": \"number\"}\n        elif ndim is not None and ndim &gt; 1:\n            # Nested arrays\n            items_schema = {\"type\": \"number\"}\n            for _ in range(ndim - 1):\n                items_schema = {\"type\": \"array\", \"items\": items_schema}\n            json_schema[\"items\"] = items_schema\n\n        return json_schema\n</code></pre>"},{"location":"api/scientific_pydantic/numpy/#scientific_pydantic.numpy.NDArrayAdapter.__get_pydantic_core_schema__","title":"<code>__get_pydantic_core_schema__(_source_type: ty.Any, _handler: pydantic.GetCoreSchemaHandler) -&gt; core_schema.CoreSchema</code>","text":"<p>Get the pydantic schema for an NDArray</p> Source code in <code>src/scientific_pydantic/numpy/ndarray_adapter.py</code> <pre><code>def __get_pydantic_core_schema__(\n    self,\n    _source_type: ty.Any,\n    _handler: pydantic.GetCoreSchemaHandler,\n) -&gt; core_schema.CoreSchema:\n    \"\"\"Get the pydantic schema for an NDArray\"\"\"\n    import numpy as np\n\n    def validate(value: ty.Any) -&gt; np.typing.NDArray:\n        return self._validator(value)\n\n    def serialize(value: np.typing.NDArray) -&gt; list:\n        \"\"\"Serialize ndarray to nested lists for JSON\"\"\"\n        return value.tolist()\n\n    python_schema = core_schema.no_info_after_validator_function(\n        validate,\n        core_schema.any_schema(),\n    )\n\n    return core_schema.json_or_python_schema(\n        json_schema=core_schema.chain_schema(\n            [\n                core_schema.any_schema(),\n                core_schema.no_info_after_validator_function(\n                    validate,\n                    core_schema.any_schema(),\n                ),\n            ],\n        ),\n        python_schema=python_schema,\n        serialization=core_schema.plain_serializer_function_ser_schema(\n            serialize,\n            info_arg=False,\n            return_schema=core_schema.any_schema(),\n        ),\n    )\n</code></pre>"},{"location":"api/scientific_pydantic/numpy/#scientific_pydantic.numpy.NDArrayAdapter.__get_pydantic_json_schema__","title":"<code>__get_pydantic_json_schema__(_core_schema: core_schema.CoreSchema, _handler: pydantic.GetJsonSchemaHandler) -&gt; JsonSchemaValue</code>","text":"<p>Generate JSON schema for the ndarray field</p> Source code in <code>src/scientific_pydantic/numpy/ndarray_adapter.py</code> <pre><code>def __get_pydantic_json_schema__(  # noqa: C901\n    self,\n    _core_schema: core_schema.CoreSchema,\n    _handler: pydantic.GetJsonSchemaHandler,\n) -&gt; JsonSchemaValue:\n    \"\"\"Generate JSON schema for the ndarray field\"\"\"\n    json_schema: dict[str, ty.Any] = {\"type\": \"array\"}\n\n    # Add description of constraints\n    constraints = []\n    if self._validator.dtype is not None:\n        constraints.append(f\"dtype: {self._validator.dtype.dtype}\")\n\n    ndim = self._validator.ndim.ndim if self._validator.ndim is not None else None\n    if ndim is not None:\n        constraints.append(f\"{ndim}D array\")\n    if self._validator.shape is not None:\n        shape_desc = \"x\".join(\n            str(s) if s is not None else \"?\" for s in self._validator.shape.shape\n        )\n        constraints.append(f\"shape: ({shape_desc})\")\n    if self._validator.ge is not None:\n        constraints.append(f\"values &gt;= {self._validator.ge.ge}\")\n    if self._validator.le is not None:\n        constraints.append(f\"values &lt;= {self._validator.le.le}\")\n    if self._validator.gt is not None:\n        constraints.append(f\"values &gt; {self._validator.gt.gt}\")\n    if self._validator.lt is not None:\n        constraints.append(f\"values &lt; {self._validator.lt.lt}\")\n    if self._validator.clip is not None:\n        constraints.append(\n            f\"clipped to [{self._validator.clip.clip[0]}, \"\n            f\"{self._validator.clip.clip[1]}]\",\n        )\n\n    if constraints:\n        json_schema[\"description\"] = \"NumPy array: \" + \", \".join(constraints)\n\n    # Add items constraint based on ndim\n    if ndim is not None and ndim &lt;= 1:\n        json_schema[\"items\"] = {\"type\": \"number\"}\n    elif ndim is not None and ndim &gt; 1:\n        # Nested arrays\n        items_schema = {\"type\": \"number\"}\n        for _ in range(ndim - 1):\n            items_schema = {\"type\": \"array\", \"items\": items_schema}\n        json_schema[\"items\"] = items_schema\n\n    return json_schema\n</code></pre>"},{"location":"api/scientific_pydantic/scipy/","title":"<code>scipy</code>","text":"<pre><code>import scientific_pydantic.scipy\n</code></pre> <p>See subpackages below.</p>"},{"location":"api/scientific_pydantic/scipy/spatial/","title":"<code>spatial</code>","text":"<pre><code>import scientific_pydantic.scipy.spatial\n</code></pre> <p>See subpackages below.</p>"},{"location":"api/scientific_pydantic/scipy/spatial/transform/","title":"<code>transform</code>","text":"<pre><code>import scientific_pydantic.scipy.spatial.transform\n</code></pre>"},{"location":"api/scientific_pydantic/scipy/spatial/transform/#scientific_pydantic.scipy.spatial.transform","title":"<code>transform</code>","text":"<p>Pydantic adapters for scipy.spatial.transform</p> <p>The current supported types are:</p> <ul> <li><code>Rotation</code> -     RotationAdapter</li> </ul>"},{"location":"api/scientific_pydantic/scipy/spatial/transform/#scientific_pydantic.scipy.spatial.transform.RotationAdapter","title":"<code>RotationAdapter</code>","text":"<p><code>pydantic</code> adapter for <code>scipy.spatial.transform.Rotation</code>.</p> Validation Options <ol> <li><code>Rotation</code> - Identity</li> <li> <p>A mapping with one of the following:</p> <ol> <li>Inputs to <code>from_quat()</code>: <pre><code>{\n  \"quat\": array_like, shape (..., 4),\n  \"scalar_first\": bool (default False),\n}\n</code></pre> This is the form used for JSON serialization as well.</li> <li>Inputs to <code>from_matrix()</code>: <pre><code>{\n  \"matrix\": array_like, shape (..., 3, 3),\n  \"assume_valid\": bool (default False, requires &gt;= 1.17.0),\n}\n</code></pre></li> <li>Inputs to <code>from_rotvec()</code>: <pre><code>{\n  \"rotvec\": array_like, shape (..., 3),\n  \"degrees\": bool (default False),\n}\n</code></pre></li> <li>Inputs to <code>from_mrp()</code>: <pre><code>{\n  \"mrp\": array_like, shape (..., 3),\n}\n</code></pre></li> <li>Inputs to <code>from_euler()</code>: <pre><code>{\n  \"euler\": {\n    \"seq\": str (see scipy docs),\n    \"angles\": float | array_like, shape (..., [1 or 2 or 3]),\n    \"degrees\": bool (default False),\n  },\n}\n</code></pre></li> <li>Inputs to <code>from_davenport()</code>: <pre><code>{\n  \"davenport\": {\n    \"axes\": array_like, shape (3,) or (..., [1 or 2 or 3], 3),\n    \"order\": \"e\" or \"extrinsic\" or \"i\" or \"intrinsic\"\n    \"angles\": float | array_like, shape (..., [1 or 2 or 3]),\n    \"degrees\": bool (default False),\n  }\n}\n</code></pre></li> </ol> </li> <li> <p><code>ArrayLike</code> - A <code>(..., 4)</code> array of quaternion(s) in scalar-last xyzw        convention.</p> </li> </ol> <p>Parameters:</p> Name Type Description Default <code>single</code> <code>bool | None</code> <p>If given as <code>True</code>, only single rotations will be accepted. Overrides <code>ndim</code> or <code>shape</code>.</p> <code>None</code> <code>ndim</code> <code>int | None</code> <p>If given, the dimensionaly of the rotations must be equal to the given value.</p> <code>None</code> <code>shape</code> <code>Sequence[int | range | slice | None] | None</code> <p>If given, provides a constraint on the shape of the given rotations. Overrides <code>ndim</code>.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import typing as ty\n&gt;&gt;&gt; from pydantic import BaseModel\n&gt;&gt;&gt; from scientific_pydantic.scipy.spatial.transform import RotationAdapter\n&gt;&gt;&gt; from scipy.spatial.transform import Rotation\n\n&gt;&gt;&gt; class Pose(BaseModel):\n...     rotation: ty.Annotated[\n...         Rotation, RotationAdapter()\n...     ]\n\n&gt;&gt;&gt; pose = Pose(rotation={\"quat\": [0, 0, 0, 1]})\n&gt;&gt;&gt; pose.model_dump_json()\n'{\"rotation\":{\"quat\":[0.0,0.0,0.0,1.0]}}'\n</code></pre> Source code in <code>src/scientific_pydantic/scipy/spatial/transform/rotation.py</code> <pre><code>class RotationAdapter:\n    \"\"\"`pydantic` adapter for `scipy.spatial.transform.Rotation`.\n\n    Validation Options\n    ------------------\n    1. `Rotation` - Identity\n    2. A mapping with one of the following:\n\n        1. Inputs to [`from_quat()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.from_quat.html#scipy.spatial.transform.Rotation.from_quat):\n        ```python\n        {\n          \"quat\": array_like, shape (..., 4),\n          \"scalar_first\": bool (default False),\n        }\n        ```\n        This is the form used for JSON serialization as well.\n        2. Inputs to [`from_matrix()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.from_matrix.html#scipy.spatial.transform.Rotation.from_matrix):\n        ```python\n        {\n          \"matrix\": array_like, shape (..., 3, 3),\n          \"assume_valid\": bool (default False, requires &gt;= 1.17.0),\n        }\n        ```\n        3. Inputs to [`from_rotvec()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.from_rotvec.html#scipy.spatial.transform.Rotation.from_rotvec):\n        ```python\n        {\n          \"rotvec\": array_like, shape (..., 3),\n          \"degrees\": bool (default False),\n        }\n        ```\n        4. Inputs to [`from_mrp()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.from_mrp.html#scipy.spatial.transform.Rotation.from_mrp):\n        ```python\n        {\n          \"mrp\": array_like, shape (..., 3),\n        }\n        ```\n        5. Inputs to [`from_euler()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.from_euler.html#scipy.spatial.transform.Rotation.from_euler):\n        ```python\n        {\n          \"euler\": {\n            \"seq\": str (see scipy docs),\n            \"angles\": float | array_like, shape (..., [1 or 2 or 3]),\n            \"degrees\": bool (default False),\n          },\n        }\n        ```\n        6. Inputs to [`from_davenport()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.from_davenport.html#scipy.spatial.transform.Rotation.from_davenport):\n        ```python\n        {\n          \"davenport\": {\n            \"axes\": array_like, shape (3,) or (..., [1 or 2 or 3], 3),\n            \"order\": \"e\" or \"extrinsic\" or \"i\" or \"intrinsic\"\n            \"angles\": float | array_like, shape (..., [1 or 2 or 3]),\n            \"degrees\": bool (default False),\n          }\n        }\n        ```\n\n    3. `ArrayLike` - A `(..., 4)` array of quaternion(s) in scalar-last xyzw\n           convention.\n\n    Parameters\n    ----------\n    single : bool | None\n        If given as `True`, only single rotations will be accepted. Overrides\n        `ndim` or `shape`.\n    ndim : int | None\n        If given, the dimensionaly of the rotations must be equal to the given\n        value.\n    shape : Sequence[int | range | slice | None] | None\n        If given, provides a constraint on the shape of the given rotations.\n        Overrides `ndim`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import typing as ty\n    &gt;&gt;&gt; from pydantic import BaseModel\n    &gt;&gt;&gt; from scientific_pydantic.scipy.spatial.transform import RotationAdapter\n    &gt;&gt;&gt; from scipy.spatial.transform import Rotation  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; class Pose(BaseModel):\n    ...     rotation: ty.Annotated[\n    ...         Rotation, RotationAdapter()\n    ...     ]  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; pose = Pose(rotation={\"quat\": [0, 0, 0, 1]})\n    &gt;&gt;&gt; pose.model_dump_json()\n    '{\"rotation\":{\"quat\":[0.0,0.0,0.0,1.0]}}'\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        single: bool | None = None,\n        ndim: int | None = None,\n        shape: Sequence[EllipsisLiteral | int | range | slice | None] | None = None,\n    ) -&gt; None:\n\n        self._shape_spec: (\n            Sequence[types.EllipsisType | int | range | slice | None] | None\n        ) = None\n        if single:\n            self._shape_spec = ()\n        elif shape is not None:\n            self._shape_spec = shape\n        elif ndim is not None:\n            self._shape_spec = (None,) * ndim\n\n        if not _supports_shape() and (\n            (shape is not None and len(shape) &gt; 1)\n            or (ndim is not None and ndim not in (0, 1))\n        ):\n            msg = \"N-D shape constraints on Rotation require scipy &gt;= 1.17.0\"\n            raise pydantic.PydanticSchemaGenerationError(msg)\n\n    def __get_pydantic_core_schema__(\n        self,\n        source_type: ty.Any,\n        handler: GetCoreSchemaHandler,\n    ) -&gt; CoreSchema:\n        \"\"\"Get the pydantic schema for this type\"\"\"\n        from scipy.spatial.transform import Rotation\n\n        del handler\n\n        if source_type is not Rotation:\n            msg = (\n                \"RotationAdapter is only usable with \"\n                f\"scipy.spatial.transform.Rotation, not {source_type}.\"\n            )\n            raise pydantic.PydanticSchemaGenerationError(msg)\n\n        # Accept any Python object and run our validator.\n        python_schema = core_schema.no_info_plain_validator_function(\n            _validate_rotation,\n        )\n        if self._shape_spec is not None:\n            spec = self._shape_spec\n\n            def _val(x: Rotation) -&gt; Rotation:\n                shape = (\n                    x.shape if _supports_shape() else (() if x.single else (len(x),))\n                )\n                if validate_shape(shape, spec):\n                    return x\n\n                err_t = \"invalid_rotation_shape\"\n                msg = \"Rotation object shape {shape} did not match spec {spec}\"\n                raise PydanticCustomError(err_t, msg, {\"shape\": shape, \"spec\": spec})\n\n            python_schema = core_schema.chain_schema(\n                [\n                    python_schema,\n                    core_schema.no_info_plain_validator_function(_val),\n                ]\n            )\n\n        # When deserialising from JSON/dict Pydantic passes a Python object\n        # after JSON parsing, so the same validator works for both paths.\n        return core_schema.json_or_python_schema(\n            json_schema=python_schema,\n            python_schema=python_schema,\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                _rotation_to_dict,\n                when_used=\"json-unless-none\",\n                return_schema=core_schema.dict_schema(),\n            ),\n        )\n</code></pre>"},{"location":"api/scientific_pydantic/scipy/spatial/transform/#scientific_pydantic.scipy.spatial.transform.RotationAdapter.__get_pydantic_core_schema__","title":"<code>__get_pydantic_core_schema__(source_type: ty.Any, handler: GetCoreSchemaHandler) -&gt; CoreSchema</code>","text":"<p>Get the pydantic schema for this type</p> Source code in <code>src/scientific_pydantic/scipy/spatial/transform/rotation.py</code> <pre><code>def __get_pydantic_core_schema__(\n    self,\n    source_type: ty.Any,\n    handler: GetCoreSchemaHandler,\n) -&gt; CoreSchema:\n    \"\"\"Get the pydantic schema for this type\"\"\"\n    from scipy.spatial.transform import Rotation\n\n    del handler\n\n    if source_type is not Rotation:\n        msg = (\n            \"RotationAdapter is only usable with \"\n            f\"scipy.spatial.transform.Rotation, not {source_type}.\"\n        )\n        raise pydantic.PydanticSchemaGenerationError(msg)\n\n    # Accept any Python object and run our validator.\n    python_schema = core_schema.no_info_plain_validator_function(\n        _validate_rotation,\n    )\n    if self._shape_spec is not None:\n        spec = self._shape_spec\n\n        def _val(x: Rotation) -&gt; Rotation:\n            shape = (\n                x.shape if _supports_shape() else (() if x.single else (len(x),))\n            )\n            if validate_shape(shape, spec):\n                return x\n\n            err_t = \"invalid_rotation_shape\"\n            msg = \"Rotation object shape {shape} did not match spec {spec}\"\n            raise PydanticCustomError(err_t, msg, {\"shape\": shape, \"spec\": spec})\n\n        python_schema = core_schema.chain_schema(\n            [\n                python_schema,\n                core_schema.no_info_plain_validator_function(_val),\n            ]\n        )\n\n    # When deserialising from JSON/dict Pydantic passes a Python object\n    # after JSON parsing, so the same validator works for both paths.\n    return core_schema.json_or_python_schema(\n        json_schema=python_schema,\n        python_schema=python_schema,\n        serialization=core_schema.plain_serializer_function_ser_schema(\n            _rotation_to_dict,\n            when_used=\"json-unless-none\",\n            return_schema=core_schema.dict_schema(),\n        ),\n    )\n</code></pre>"},{"location":"api/scientific_pydantic/shapely/","title":"<code>shapely</code>","text":"<pre><code>import scientific_pydantic.shapely\n</code></pre>"},{"location":"api/scientific_pydantic/shapely/#scientific_pydantic.shapely","title":"<code>shapely</code>","text":"<p>Type adaptors for shapely</p> <p>The current supported types are:</p> <ul> <li>Geometry types - GeometryAdapter</li> </ul>"},{"location":"api/scientific_pydantic/shapely/#scientific_pydantic.shapely.CoordinateBounds","title":"<code>CoordinateBounds</code>  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Bounds checks for coordinates</p> Show JSON schema: <pre><code>{\n  \"description\": \"Bounds checks for coordinates\",\n  \"properties\": {\n    \"gt\": {\n      \"anyOf\": [\n        {\n          \"type\": \"number\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"All coordinates must be &gt; this value\",\n      \"title\": \"Gt\"\n    },\n    \"ge\": {\n      \"anyOf\": [\n        {\n          \"type\": \"number\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"All coordinates must be &gt;= this value\",\n      \"title\": \"Ge\"\n    },\n    \"lt\": {\n      \"anyOf\": [\n        {\n          \"type\": \"number\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"All coordinates must be &lt; this value\",\n      \"title\": \"Lt\"\n    },\n    \"le\": {\n      \"anyOf\": [\n        {\n          \"type\": \"number\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"All coordinates must be &lt;= this value\",\n      \"title\": \"Le\"\n    }\n  },\n  \"title\": \"CoordinateBounds\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>gt</code>                 (<code>float | None</code>)             </li> <li> <code>ge</code>                 (<code>float | None</code>)             </li> <li> <code>lt</code>                 (<code>float | None</code>)             </li> <li> <code>le</code>                 (<code>float | None</code>)             </li> </ul> Source code in <code>src/scientific_pydantic/shapely/adapters.py</code> <pre><code>class CoordinateBounds(pydantic.BaseModel):\n    \"\"\"Bounds checks for coordinates\"\"\"\n\n    gt: float | None = pydantic.Field(\n        default=None, description=\"All coordinates must be &gt; this value\"\n    )\n    ge: float | None = pydantic.Field(\n        default=None, description=\"All coordinates must be &gt;= this value\"\n    )\n    lt: float | None = pydantic.Field(\n        default=None, description=\"All coordinates must be &lt; this value\"\n    )\n    le: float | None = pydantic.Field(\n        default=None, description=\"All coordinates must be &lt;= this value\"\n    )\n\n    def __call__(self, coordinates: ArrayLike) -&gt; NDArray:\n        \"\"\"Validate the bounds on the given coordinates\"\"\"\n        return NDArrayValidator.from_kwargs(**self.model_dump())(coordinates)\n</code></pre>"},{"location":"api/scientific_pydantic/shapely/#scientific_pydantic.shapely.CoordinateBounds.gt","title":"<code>gt: float | None = None</code>  <code>pydantic-field</code>","text":"<p>All coordinates must be &gt; this value</p>"},{"location":"api/scientific_pydantic/shapely/#scientific_pydantic.shapely.CoordinateBounds.ge","title":"<code>ge: float | None = None</code>  <code>pydantic-field</code>","text":"<p>All coordinates must be &gt;= this value</p>"},{"location":"api/scientific_pydantic/shapely/#scientific_pydantic.shapely.CoordinateBounds.lt","title":"<code>lt: float | None = None</code>  <code>pydantic-field</code>","text":"<p>All coordinates must be &lt; this value</p>"},{"location":"api/scientific_pydantic/shapely/#scientific_pydantic.shapely.CoordinateBounds.le","title":"<code>le: float | None = None</code>  <code>pydantic-field</code>","text":"<p>All coordinates must be &lt;= this value</p>"},{"location":"api/scientific_pydantic/shapely/#scientific_pydantic.shapely.CoordinateBounds.__call__","title":"<code>__call__(coordinates: ArrayLike) -&gt; NDArray</code>","text":"<p>Validate the bounds on the given coordinates</p> Source code in <code>src/scientific_pydantic/shapely/adapters.py</code> <pre><code>def __call__(self, coordinates: ArrayLike) -&gt; NDArray:\n    \"\"\"Validate the bounds on the given coordinates\"\"\"\n    return NDArrayValidator.from_kwargs(**self.model_dump())(coordinates)\n</code></pre>"},{"location":"api/scientific_pydantic/shapely/#scientific_pydantic.shapely.GeometryAdapter","title":"<code>GeometryAdapter</code>","text":"<p>A pydantic adapter for shapely geometry</p> <p>This adapter can be used with the various shapely Geometry Types.</p> <p>This adapter will constrain the type of geometry accepted by the field according to the type annotation. For example:</p> <pre><code>ty.Annotated[shapely.Polygon, GeometryAdapter()]\n</code></pre> <p>would accept only <code>Polygon</code>s. Unions are also accepted, as well as <code>shapely.geometry.base.BaseGeometry</code>, which would accept any of the geometry types.</p> Validation Options <ol> <li>Geometry types - Identity.</li> <li><code>str</code> - A GeoJSON or WKT representation of the geometry</li> <li><code>Mapping</code> - A GeoJSON mapping</li> <li><code>__geo_interface__</code> - Any Python object which implements    <code>.__geo_interface__</code>. This is used for the JSON serialization.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>dimensionality</code> <code>Literal[2, 3] | None</code> <p>If given, constrains the accepted geometry to either have (3) or not have (2) a third dimension to all coordinates.</p> <code>None</code> <code>x_bounds</code> <code>CoordinateBounds | None</code> <p>If given, bounds for the x-coordinates of the geometry.</p> <code>None</code> <code>y_bounds</code> <code>CoordinateBounds | None</code> <p>If given, bounds for the y-coordinates of the geometry.</p> <code>None</code> <code>z_bounds</code> <code>CoordinateBounds | None</code> <p>If given, bounds for the z-coordinates of the geometry.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pydantic\n&gt;&gt;&gt; import shapely\n&gt;&gt;&gt; from scientific_pydantic.shapely import (\n...     GeometryAdapter,\n... )\n\n&gt;&gt;&gt; class Model(pydantic.BaseModel):\n...     mp: ty.Annotated[\n...         shapely.MultiPoint, GeometryAdapter()\n...     ]\n\n&gt;&gt;&gt; Model(\n...     mp={\n...         \"type\": \"MultiPoint\",\n...         \"coordinates\": [[1, 2], [3, 4]],\n...     },\n... )\nModel(mp=&lt;MULTIPOINT ((1 2), (3 4))&gt;)\n</code></pre> Source code in <code>src/scientific_pydantic/shapely/adapters.py</code> <pre><code>class GeometryAdapter:\n    \"\"\"A pydantic adapter for shapely geometry\n\n    This adapter can be used with the various shapely\n    [Geometry Types](https://shapely.readthedocs.io/en/latest/geometry.html#geometry-types).\n\n    This adapter will constrain the type of geometry accepted by the field\n    according to the type annotation. For example:\n\n    ```python\n    ty.Annotated[shapely.Polygon, GeometryAdapter()]\n    ```\n\n    would accept only `Polygon`s. Unions are also accepted, as well as\n    `shapely.geometry.base.BaseGeometry`, which would accept any of the geometry\n    types.\n\n    Validation Options\n    ------------------\n    1. Geometry types - Identity.\n    2. `str` - A GeoJSON or WKT representation of the geometry\n    3. `Mapping` - A GeoJSON mapping\n    4. `__geo_interface__` - Any Python object which implements\n       `.__geo_interface__`. This is used for the JSON serialization.\n\n    Parameters\n    ----------\n    dimensionality\n        If given, constrains the accepted geometry to either have (3) or not\n        have (2) a third dimension to all coordinates.\n    x_bounds\n        If given, bounds for the x-coordinates of the geometry.\n    y_bounds\n        If given, bounds for the y-coordinates of the geometry.\n    z_bounds\n        If given, bounds for the z-coordinates of the geometry.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pydantic\n    &gt;&gt;&gt; import shapely\n    &gt;&gt;&gt; from scientific_pydantic.shapely import (\n    ...     GeometryAdapter,\n    ... )  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; class Model(pydantic.BaseModel):\n    ...     mp: ty.Annotated[\n    ...         shapely.MultiPoint, GeometryAdapter()\n    ...     ]  # doctest: +NORMALIZE_WHITESPACE\n    &lt;BLANKLINE&gt;\n    &gt;&gt;&gt; Model(\n    ...     mp={\n    ...         \"type\": \"MultiPoint\",\n    ...         \"coordinates\": [[1, 2], [3, 4]],\n    ...     },\n    ... )\n    Model(mp=&lt;MULTIPOINT ((1 2), (3 4))&gt;)\n    \"\"\"\n\n    CoordinateBounds: ty.ClassVar[type] = CoordinateBounds\n\n    def __init__(\n        self,\n        *,\n        dimensionality: ty.Literal[2, 3] | None = None,\n        x_bounds: CoordinateBounds | None = None,\n        y_bounds: CoordinateBounds | None = None,\n        z_bounds: CoordinateBounds | None = None,\n    ) -&gt; None:\n        self._validator = GeometryConstraints(\n            dimensionality=dimensionality,\n            x_bounds=x_bounds,\n            y_bounds=y_bounds,\n            z_bounds=z_bounds,\n        )\n\n    def __get_pydantic_core_schema__(\n        self,\n        source_type: ty.Any,\n        _handler: pydantic.GetCoreSchemaHandler,\n    ) -&gt; core_schema.CoreSchema:\n        \"\"\"Get the pydantic schema for the shapely geometry\"\"\"\n        import shapely\n\n        allowable_types = _get_allowable_types(source_type)\n\n        def validate(value: ty.Any) -&gt; ty.Any:\n            if isinstance(value, shapely.geometry.base.BaseGeometry):\n                pass\n            elif isinstance(value, str):\n                value = _parse_str(value)\n            elif (is_mapping := isinstance(value, Mapping)) or hasattr(\n                value, \"__geo_interface__\"\n            ):\n                # shapely raises an AttributeError in this case\n                if is_mapping and \"type\" not in value:\n                    msg = 'Invalid GeoJSON mapping, missing \"type\"'\n                    err_t = \"invalid_geojson\"\n                    raise PydanticCustomError(err_t, msg)\n                try:\n                    value = shapely.geometry.shape(value)  # type: ignore[bad-argument-type]\n                except (KeyError, ValueError, shapely.errors.ShapelyError) as e:\n                    msg = \"Invalid GeoJSON mapping ({e})\"\n                    err_t = \"invalid_geojson\"\n                    raise PydanticCustomError(err_t, msg, {\"e\": e}) from e\n\n            if not isinstance(value, allowable_types):\n                msg = \"Value was of incorrect type: {t}. {exp}\"\n                subs = {\"t\": type(value).__name__}\n                if len(allowable_types) == 1:\n                    subs[\"exp\"] = f\"Expected {allowable_types[0].__name__}.\"\n                else:\n                    subs[\"exp\"] = (\n                        \"Expected one of: \"\n                        f\"{', '.join(t.__name__ for t in allowable_types)}.\"\n                    )\n                err_t = \"geometry_type\"\n                raise PydanticCustomError(err_t, msg, subs)\n\n            return self._validator(value)\n\n        def serialize(geom: shapely.geometry.base.BaseGeometry) -&gt; dict[str, ty.Any]:\n            return geom.__geo_interface__\n\n        schema = core_schema.no_info_plain_validator_function(validate)\n        return core_schema.json_or_python_schema(\n            json_schema=core_schema.chain_schema(\n                [\n                    core_schema.union_schema(\n                        [core_schema.str_schema(), core_schema.dict_schema()]\n                    ),\n                    schema,\n                ]\n            ),\n            python_schema=schema,\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                serialize,\n                return_schema=core_schema.dict_schema(),\n            ),\n        )\n\n    def __get_pydantic_json_schema__(\n        self,\n        core_schema: core_schema.CoreSchema,\n        handler: pydantic.GetJsonSchemaHandler,\n    ) -&gt; JsonSchemaValue:\n        \"\"\"Get the JSON schema for this field\"\"\"\n        json_schema = handler(core_schema)\n        json_schema = handler.resolve_ref_schema(json_schema)\n        json_schema[\"description\"] = json_schema.get(\n            \"description\", \"No user description\"\n        ) + (\n            \" (WKT string or GeoJSON object with the following constraints: \"\n            f\"{self._validator.summary()})\"\n        )\n        return json_schema\n</code></pre>"},{"location":"api/scientific_pydantic/shapely/#scientific_pydantic.shapely.GeometryAdapter.__get_pydantic_core_schema__","title":"<code>__get_pydantic_core_schema__(source_type: ty.Any, _handler: pydantic.GetCoreSchemaHandler) -&gt; core_schema.CoreSchema</code>","text":"<p>Get the pydantic schema for the shapely geometry</p> Source code in <code>src/scientific_pydantic/shapely/adapters.py</code> <pre><code>def __get_pydantic_core_schema__(\n    self,\n    source_type: ty.Any,\n    _handler: pydantic.GetCoreSchemaHandler,\n) -&gt; core_schema.CoreSchema:\n    \"\"\"Get the pydantic schema for the shapely geometry\"\"\"\n    import shapely\n\n    allowable_types = _get_allowable_types(source_type)\n\n    def validate(value: ty.Any) -&gt; ty.Any:\n        if isinstance(value, shapely.geometry.base.BaseGeometry):\n            pass\n        elif isinstance(value, str):\n            value = _parse_str(value)\n        elif (is_mapping := isinstance(value, Mapping)) or hasattr(\n            value, \"__geo_interface__\"\n        ):\n            # shapely raises an AttributeError in this case\n            if is_mapping and \"type\" not in value:\n                msg = 'Invalid GeoJSON mapping, missing \"type\"'\n                err_t = \"invalid_geojson\"\n                raise PydanticCustomError(err_t, msg)\n            try:\n                value = shapely.geometry.shape(value)  # type: ignore[bad-argument-type]\n            except (KeyError, ValueError, shapely.errors.ShapelyError) as e:\n                msg = \"Invalid GeoJSON mapping ({e})\"\n                err_t = \"invalid_geojson\"\n                raise PydanticCustomError(err_t, msg, {\"e\": e}) from e\n\n        if not isinstance(value, allowable_types):\n            msg = \"Value was of incorrect type: {t}. {exp}\"\n            subs = {\"t\": type(value).__name__}\n            if len(allowable_types) == 1:\n                subs[\"exp\"] = f\"Expected {allowable_types[0].__name__}.\"\n            else:\n                subs[\"exp\"] = (\n                    \"Expected one of: \"\n                    f\"{', '.join(t.__name__ for t in allowable_types)}.\"\n                )\n            err_t = \"geometry_type\"\n            raise PydanticCustomError(err_t, msg, subs)\n\n        return self._validator(value)\n\n    def serialize(geom: shapely.geometry.base.BaseGeometry) -&gt; dict[str, ty.Any]:\n        return geom.__geo_interface__\n\n    schema = core_schema.no_info_plain_validator_function(validate)\n    return core_schema.json_or_python_schema(\n        json_schema=core_schema.chain_schema(\n            [\n                core_schema.union_schema(\n                    [core_schema.str_schema(), core_schema.dict_schema()]\n                ),\n                schema,\n            ]\n        ),\n        python_schema=schema,\n        serialization=core_schema.plain_serializer_function_ser_schema(\n            serialize,\n            return_schema=core_schema.dict_schema(),\n        ),\n    )\n</code></pre>"},{"location":"api/scientific_pydantic/shapely/#scientific_pydantic.shapely.GeometryAdapter.__get_pydantic_json_schema__","title":"<code>__get_pydantic_json_schema__(core_schema: core_schema.CoreSchema, handler: pydantic.GetJsonSchemaHandler) -&gt; JsonSchemaValue</code>","text":"<p>Get the JSON schema for this field</p> Source code in <code>src/scientific_pydantic/shapely/adapters.py</code> <pre><code>def __get_pydantic_json_schema__(\n    self,\n    core_schema: core_schema.CoreSchema,\n    handler: pydantic.GetJsonSchemaHandler,\n) -&gt; JsonSchemaValue:\n    \"\"\"Get the JSON schema for this field\"\"\"\n    json_schema = handler(core_schema)\n    json_schema = handler.resolve_ref_schema(json_schema)\n    json_schema[\"description\"] = json_schema.get(\n        \"description\", \"No user description\"\n    ) + (\n        \" (WKT string or GeoJSON object with the following constraints: \"\n        f\"{self._validator.summary()})\"\n    )\n    return json_schema\n</code></pre>"}]}